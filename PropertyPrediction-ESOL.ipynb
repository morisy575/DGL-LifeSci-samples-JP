{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Property Prediction - 化合物の水溶解度予測\n",
    "\n",
    "分子構造は、元素とその位置、つまり3次元立体構造データとして表現されます。本ノートブックでは、DGL-LifeSciを用いて、分子構造のデータをそのまま入力して物質の物性値を予測するタスク（Property Prediction）を行います。\n",
    "- 本ノートブックでは、分子構造に基づいて低分子化合物の水への溶解度予測を行います。本章で扱うデータは、ESOLのデータセットです。[ESOL（Estimated SOLubility）](https://pubs.acs.org/doi/10.1021/ci034243x)のデータセットは、化合物の水への溶解度に関するパブリックデータセットです（元論文の著者名から「Delaneyデータセット」とも呼ばれることがあります）。[MoleculeNet](https://pubs.rsc.org/en/content/articlelanding/2018/sc/c7sc02664a)と呼ばれる分子機械学習ベンチマークデータセットのうちの一つで、1128の化合物のデータが含まれています。\n",
    "- 今回扱うタスクは、入力となる化合物の水への溶解度の数値を予測する問題（回帰問題, Regression Task）となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Using pre-trained model\n",
    "- 例えば「試しに予測してみたい化合物はあるけれどGNNを1から学習させるのはハードルが高い...」という方もいらっしゃるかと思います。\n",
    "- DGL-LifeSciではいくつかの有名なデータセットを用いて事前に学習されたモデルを提供しています。（一覧はこちら https://lifesci.dgl.ai/api/model.pretrain.html#api ）\n",
    "- 1.1では事前学習済みモデルを用いることで、手元で機械学習のトレーニングを行うことなく、すぐに分子特性予測を行うことを体感します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "DGL-LifeSciおよび必要なライブラリをインストールします。\n",
    "- DGL-LifeSci\n",
    "- Python 3.6+\n",
    "- PyTorch 1.5.0+\n",
    "- DGL 0.7.0+\n",
    "- RDKit 2018.09.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install dgl\n",
    "!pip install dgllife\n",
    "!conda install -c rdkit -y rdkit==2018.09.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with pre-trained model\n",
    "ESOLのデータセットで事前に学習されたモデルをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dgllife.data import ESOL\n",
    "from dgllife.model import load_pretrained\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer\n",
    "\n",
    "model = load_pretrained('GCN_canonical_ESOL') # Pretrained model loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではロードしたモデルの構造を見てみましょう。 （ちなみに本来`model.eval()`は、モデルを推論モードに切り替えるためのものです。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にデータセットをロードします。ここには学習に用いられた1128個の化合物に関するデータが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ESOL(smiles_to_bigraph, node_featurizer=CanonicalAtomFeaturizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、ロードしたデータセットの中から一つ選び、中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles, g, label = dataset[0]\n",
    "print('SMILES: ', smiles)\n",
    "print('DGLGraph: ', g)\n",
    "print('Node Features: ',g.ndata['h'], g.ndata['h'].size())\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各出力は以下のような意味となります。\n",
    "- SMILES：対象としている化合物をSMILES記法で表した文字列\n",
    "- DGLGraph：化合物をグラフ形式（DGLGraph）で表したオブジェクト\n",
    "    - Node Features： 分子内の原子（グラフにおけるノード）に関係する特徴量の集まり。その原子が何か、隣接する水素原子の数など、各原子に関わる情報を数値化したものになります。（今回使用している`CanonicalAtomFeaturizer`についてはこちらをご覧ください https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html)\n",
    "- Label: 予測すべき値となる水溶解度(logS = $\\log_{10} \\frac{mol}{L}$)を表しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選択された化合物の構造をRDKitを用いて確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "mol = [Chem.MolFromSmiles(smiles)]\n",
    "SVG(Draw.MolsToGridImage(mol, molsPerRow=1, useSVG=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、選択された化合物に対して、事前に学習されたモデルを用いて水溶解度を予測していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop the node features\n",
    "feats = g.ndata.pop('h')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    label_pred = model(g, feats)\n",
    "\n",
    "# Mask non-existing labels\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Train your own model on a CSV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 実際に分子特性予測を行う場合、皆さんがそれぞれお持ちのカスタムデータセットを使ったモデルの作成を検討されると思います。\n",
    "- DGL-LifeSciには、学習に使いたいデータ（CSVファイル）で用意していただければ、コマンドライン一行でモデルの学習 / 推論ができるプログラムが用意されています。\n",
    "- 本節ではDGL-LifeSciが提供するプログラムを用いて化合物の水溶解度を予測するモデルの学習・推論を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本ハンズオンでは、化合物の水溶解度に関するCSVデータとして、1.1でも使用したESOLデータセットを使用します。もしお手持ちのデータでモデルの学習ないし推論を試したい場合は、以下で説明する形式のCSVファイルを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a CSV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは対象データをCSV形式で準備する必要があります。ESOLデータセットをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data.utils import download, _get_dgl_url, extract_archive\n",
    "\n",
    "url = 'dataset/ESOL.zip'\n",
    "data_path = 'ESOL.zip'\n",
    "download(_get_dgl_url(url), path=data_path)\n",
    "extract_archive(data_path, './ESOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ESOL/delaney-processed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータは上のようになっています。\n",
    "複数あるカラムのうち、今回予測対象となる水溶解度は`measured log solubility in mols per litre`であり、`smiles`カラムが入力となるSMILES文字列となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download sample scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コマンドラインで実行できるプログラムはDGL-LifeSciの公式リポジトリにあります。まず、リポジトリをクローンします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/awslabs/dgl-lifesci.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp ./dgl-lifesci/examples/property_prediction/csv_data_configuration/ -r ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはデータセットについて分析してみましょう。化合物について簡単に分析するためのスクリプトが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./csv_data_configuration/analysis.py -c ./ESOL/delaney-processed.csv -sc 'smiles' -p ./analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./analysis_results/summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd ./csv_data_configuration/\n",
    "!python ./regression_train.py -c ../ESOL/delaney-processed.csv -sc 'smiles' -t 'measured log solubility in mols per litre' -me rmse -nw 0 -p ../regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よりモデル性能を向上させるため、モデルのハイパーパラメータの最適化を行います。\n",
    "`-ne <num_trials>`のオプションを加えることで、`<num_trials>`で指定した回数分ハイパーパラメータの探索(ベイズ最適化)を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# With Hyper Parameter Search\n",
    "%cd ../csv_data_configuration/\n",
    "!python regression_train.py -ne 5 -c ../../../../ESOL/delaney-processed.csv -sc 'smiles' -t 'measured log solubility in mols per litre' -me rmse -nw 0 -p ../../../../regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo \n",
    "テストセット用CSVファイルを別に作って残しといてそれで推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Train your own models using Amazon SageMaker Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'dgllifesci/esol/dataset'\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをS3にアップロード\n",
    "%cd ../\n",
    "!aws s3 cp ./ESOL/delaney-processed.csv s3://{bucket}/{prefix}/delaney-processed.csv\n",
    "!aws s3 ls s3://{bucket}/{prefix}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input = sagemaker.inputs.TrainingInput(s3_data=f's3://{bucket}/{prefix}/delaney-processed.csv', content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!touch dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt\n",
    "!echo \"dgl-cu101 -f https://data.dgl.ai/wheels/repo.html\\ndgllife\\nrdkit-pypi\" > dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt\n",
    "!cat dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# import json\n",
    "# # JSON encode hyperparameters\n",
    "# def json_encode_hyperparameters(hyperparameters):\n",
    "#     return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "# hyperparameters = json_encode_hyperparameters(\n",
    "#     {\n",
    "#         'dataset':'Tox21',\n",
    "#         'model':'GCN',\n",
    "#         'featurizer-type':'canonical',\n",
    "#         'sagemaker_program':'classification.py',\n",
    "#         'sagemaker_submit_directory':inputs\n",
    "#     }\n",
    "# )\n",
    "\n",
    "hyperparameters = {\n",
    "    'csv-name': 'delaney-processed.csv',\n",
    "    'model':'GCN',\n",
    "    'atom-featurizer-type':'canonical',\n",
    "    'smiles-column':'smiles',\n",
    "    'task-names':\"measured log solubility in mols per litre\",\n",
    "    'metric':'rmse',\n",
    "    'num-workers': 0,\n",
    "    'num-evals': 10,   \n",
    "}\n",
    "\n",
    "# Create estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"regression_train_sagemaker.py\",\n",
    "    source_dir=\"./csv_data_configuration/\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 学習を開始\n",
    "estimator.fit({'train':s3_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.latest_training_job.job_name\n",
    "# !aws s3 cp {estimator.output_path}{estimator.latest_training_job.job_name}/output/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Train your own models using Amazon SageMaker Training Job with Custom Container (※ Optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### メモ\n",
    "- requirementの`RDKit 2018.09.3`がconda installでないとinstallできないので、document通りに確実に動く環境を整えるならこっち（のはず）。\n",
    "- ただし`pip install rdkit-pypl`でも対応できる(2022年12月現在)。version 2018.09.3のものはサポートされていないが、dglaiの方のハンズオンではこれで対応している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "SageMakerで学習を実行するにあたり必要なライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "docker_name=sagemaker-dgllifesci-py36\n",
    "sm-docker build . -f ./container/Dockerfile --repository $docker_name:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf source.tar.gz utils.py classification.py ./configures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'dgl-lifesci/property_prediction/code'\n",
    "inputs = sess.upload_data(path='./source.tar.gz', bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# JSON encode hyperparameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(\n",
    "    {\n",
    "        'dataset':'Tox21',\n",
    "        'model':'GCN',\n",
    "        'featurizer-type':'canonical',\n",
    "        'sagemaker_program':'classification.py',\n",
    "        'sagemaker_submit_directory':inputs\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri = '233488627969.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-dgllifesci-py36:1.0',\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m5.4xlarge\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    sagemaker_session = sess\n",
    ")\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
