{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Property Prediction - 化合物の水溶解度予測\n",
    "\n",
    "分子構造は、元素とその位置、つまり3次元立体構造データとして表現されます。本ノートブックでは、DGL-LifeSciを用いて、分子構造のデータをそのまま入力して物質の物性値を予測するタスク（Property Prediction）を行います。\n",
    "- 本ノートブックでは、分子構造に基づいて低分子化合物の水への溶解度予測を行います。本章で扱うデータは、ESOLのデータセットです。[ESOL（Estimated SOLubility）](https://pubs.acs.org/doi/10.1021/ci034243x)のデータセットは、化合物の水への溶解度に関するパブリックデータセットです（元論文の著者名から「Delaneyデータセット」とも呼ばれることがあります）。[MoleculeNet](https://pubs.rsc.org/en/content/articlelanding/2018/sc/c7sc02664a)と呼ばれる分子機械学習ベンチマークデータセットのうちの一つで、1128の化合物のデータが含まれています。\n",
    "- 今回扱うタスクは、入力となる化合物の水への溶解度の数値を予測する問題（回帰問題, Regression Task）となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Using pre-trained model\n",
    "- 例えば「試しに予測してみたい化合物はあるけれどGNNを1から学習させるのはハードルが高い...」という方もいらっしゃるかと思います。\n",
    "- DGL-LifeSciではいくつかの有名なデータセットを用いて事前に学習されたモデルを提供しています。（一覧はこちら https://lifesci.dgl.ai/api/model.pretrain.html#api ）\n",
    "- 1.1では事前学習済みモデルを用いることで、手元で機械学習のトレーニングを行うことなく、すぐに分子特性予測を行うことを体感します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "DGL-LifeSciおよび必要なライブラリをインストールします。\n",
    "- DGL-LifeSci\n",
    "- Python 3.6+\n",
    "- PyTorch 1.5.0+\n",
    "- DGL 0.7.0+\n",
    "- RDKit 2018.09.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dgl in /opt/conda/lib/python3.6/site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from dgl) (1.19.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from dgl) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.6/site-packages (from dgl) (2.5.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from dgl) (2.25.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.1->dgl) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl) (2.10)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: dgllife in /opt/conda/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from dgllife) (1.1.5)\n",
      "Requirement already satisfied: hyperopt in /opt/conda/lib/python3.6/site-packages (from dgllife) (0.2.7)\n",
      "Requirement already satisfied: requests>=2.22.0 in /opt/conda/lib/python3.6/site-packages (from dgllife) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from dgllife) (1.19.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from dgllife) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from dgllife) (4.51.0)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.6/site-packages (from dgllife) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn<1.0,>=0.22.2 in /opt/conda/lib/python3.6/site-packages (from dgllife) (0.24.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from dgllife) (1.2.2)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.1->dgllife) (4.4.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dgllife) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dgllife) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dgllife) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.22.0->dgllife) (2020.12.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn<1.0,>=0.22.2->dgllife) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife) (1.16.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife) (0.18.2)\n",
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife) (0.10.9.7)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife) (2021.1)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.6m/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda\n",
      "\n",
      "  added / updated specs:\n",
      "    - rdkit==2018.09.3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.10.11 |       h06a4308_0         124 KB\n",
      "    certifi-2021.5.30          |   py36h06a4308_0         139 KB\n",
      "    conda-4.10.3               |   py36h06a4308_0         2.9 MB\n",
      "    libboost-1.67.0            |       h46d08c1_4        13.0 MB\n",
      "    olefile-0.46               |           py36_0          48 KB\n",
      "    openssl-1.1.1s             |       h7f8727e_0         3.6 MB\n",
      "    pillow-5.4.1               |   py36h34e0f95_0         568 KB\n",
      "    py-boost-1.67.0            |   py36h04863e7_4         278 KB\n",
      "    rdkit-2018.09.3.0          |   py36hc20afe1_1        20.2 MB  rdkit\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        40.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libboost           pkgs/main/linux-64::libboost-1.67.0-h46d08c1_4\n",
      "  olefile            pkgs/main/linux-64::olefile-0.46-py36_0\n",
      "  pillow             pkgs/main/linux-64::pillow-5.4.1-py36h34e0f95_0\n",
      "  py-boost           pkgs/main/linux-64::py-boost-1.67.0-py36h04863e7_4\n",
      "  rdkit              rdkit/linux-64::rdkit-2018.09.3.0-py36hc20afe1_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2021.4.13-h06a4308_1 --> 2022.10.11-h06a4308_0\n",
      "  certifi                          2020.12.5-py36h06a4308_0 --> 2021.5.30-py36h06a4308_0\n",
      "  conda                               4.10.1-py36h06a4308_1 --> 4.10.3-py36h06a4308_0\n",
      "  openssl                                 1.1.1k-h27cfd23_0 --> 1.1.1s-h7f8727e_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "rdkit-2018.09.3.0    | 20.2 MB   | ##################################### | 100% \n",
      "conda-4.10.3         | 2.9 MB    | ##################################### | 100% \n",
      "certifi-2021.5.30    | 139 KB    | ##################################### | 100% \n",
      "py-boost-1.67.0      | 278 KB    | ##################################### | 100% \n",
      "libboost-1.67.0      | 13.0 MB   | ##################################### | 100% \n",
      "olefile-0.46         | 48 KB     | ##################################### | 100% \n",
      "openssl-1.1.1s       | 3.6 MB    | ##################################### | 100% \n",
      "pillow-5.4.1         | 568 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 124 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl\n",
    "!pip install dgllife\n",
    "!conda install -c rdkit -y rdkit==2018.09.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference with pre-trained model\n",
    "ESOLのデータセットで事前に学習されたモデルをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GCN_canonical_ESOL_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gcn_canonical_esol.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dgllife.data import ESOL\n",
    "from dgllife.model import load_pretrained\n",
    "from dgllife.utils import smiles_to_bigraph, CanonicalAtomFeaturizer\n",
    "\n",
    "model = load_pretrained('GCN_canonical_ESOL') # Pretrained model loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではロードしたモデルの構造を見てみましょう。 （ちなみに本来`model.eval()`は、モデルを推論モードに切り替えるためのものです。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNPredictor(\n",
       "  (gnn): GCN(\n",
       "    (gnn_layers): ModuleList(\n",
       "      (0): GCNLayer(\n",
       "        (graph_conv): GraphConv(in=74, out=128, normalization=none, activation=<function relu at 0x7f80bbb278c8>)\n",
       "        (dropout): Dropout(p=0.0004181672129021179, inplace=False)\n",
       "        (res_connection): Linear(in_features=74, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (readout): WeightedSumAndMax(\n",
       "    (weight_and_sum): WeightAndSum(\n",
       "      (atom_weighting): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "        (1): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predict): MLPPredictor(\n",
       "    (predict): Sequential(\n",
       "      (0): Dropout(p=0.0004181672129021179, inplace=False)\n",
       "      (1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にデータセットをロードします。ここには学習に用いられた1128個の化合物に関するデータが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/1128\n"
     ]
    }
   ],
   "source": [
    "dataset = ESOL(smiles_to_bigraph, node_featurizer=CanonicalAtomFeaturizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、ロードしたデータセットの中から一つ選び、中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES:  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)C(O)C3O \n",
      "DGLGraph:  Graph(num_nodes=32, num_edges=68,\n",
      "      ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "Node Features:  tensor([[1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.]]) torch.Size([32, 74])\n",
      "Label:  tensor([-0.7700])\n"
     ]
    }
   ],
   "source": [
    "smiles, g, label = dataset[0]\n",
    "print('SMILES: ', smiles)\n",
    "print('DGLGraph: ', g)\n",
    "print('Node Features: ',g.ndata['h'], g.ndata['h'].size())\n",
    "print('Label: ', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各出力は以下のような意味となります。\n",
    "- SMILES：対象としている化合物をSMILES記法で表した文字列\n",
    "- DGLGraph：化合物をグラフ形式（DGLGraph）で表したオブジェクト\n",
    "    - Node Features： 分子内の原子（グラフにおけるノード）に関係する特徴量の集まり。その原子が何か、隣接する水素原子の数など、各原子に関わる情報を数値化したものになります。（今回使用している`CanonicalAtomFeaturizer`についてはこちらをご覧ください https://lifesci.dgl.ai/generated/dgllife.utils.CanonicalAtomFeaturizer.html)\n",
    "- Label: 予測すべき値となる水溶解度(logS = $\\log_{10} \\frac{mol}{L}$)を表しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "選択された化合物の構造をRDKitを用いて確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"200px\" version=\"1.1\" width=\"200px\" xml:space=\"preserve\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:rdkit=\"http://www.rdkit.org/xml\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<rect height=\"200\" style=\"opacity:1.0;fill:#FFFFFF;stroke:none\" width=\"200\" x=\"0\" y=\"0\"> </rect>\n",
       "<path d=\"M 183.763,114.943 184.812,107.171\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 184.812,107.171 185.862,99.3979\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 185.862,99.3979 170.939,87.8681\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 170.939,87.8681 163.683,90.8452\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 163.683,90.8452 156.428,93.8223\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 170.939,87.8681 173.462,69.1795\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 150.557,92.7588 144.563,88.1279\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 144.563,88.1279 138.569,83.497\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 138.569,83.497 131.314,86.4741\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 131.314,86.4741 124.058,89.4512\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 138.569,83.497 141.093,64.8084\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 120.698,93.7987 119.649,101.572\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 119.649,101.572 118.599,109.344\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 118.599,109.344 101.152,116.503\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 101.152,116.503 95.1586,111.872\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 95.1586,111.872 89.1649,107.241\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 101.152,116.503 98.6287,135.192\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 83.2939,106.178 76.0383,109.155\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 76.0383,109.155 68.7827,112.132\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 68.7827,112.132 62.789,107.501\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 62.789,107.501 56.7953,102.87\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 68.7827,112.132 66.2591,130.821\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 54.2842,97.459 55.3338,89.6863\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 55.3338,89.6863 56.3834,81.9135\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 56.3834,81.9135 73.8301,74.7548\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 56.3834,81.9135 41.4605,70.3836\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 73.8301,74.7548 81.1913,71.7343\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 81.1913,71.7343 88.5525,68.7138\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 77.4702,77.3379 83.7272,74.7705\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 83.7272,74.7705 89.9842,72.2031\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 74.6067,70.3593 80.8637,67.7919\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 80.8637,67.7919 87.1207,65.2245\" style=\"fill:none;fill-rule:evenodd;stroke:#0000FF;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 41.4605,70.3836 43.9842,51.6951\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 38.1013,67.0756 39.8679,53.9936\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 41.4605,70.3836 24.0139,77.5424\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 43.9842,51.6951 29.0612,40.1652\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 29.0612,40.1652 11.6146,47.3239\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 27.8759,44.7283 15.6633,49.7395\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 11.6146,47.3239 9.09091,66.0125\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 9.09091,66.0125 24.0139,77.5424\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 13.6353,64.7574 24.0814,72.8283\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 66.2591,130.821 60.3656,133.239\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 60.3656,133.239 54.4722,135.657\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 66.2591,130.821 81.182,142.35\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 81.182,142.35 80.1324,150.123\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 80.1324,150.123 79.0828,157.896\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 81.182,142.35 98.6287,135.192\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 98.6287,135.192 104.056,139.385\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 104.056,139.385 109.484,143.578\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 141.093,64.8084 135.665,60.615\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 135.665,60.615 130.238,56.4216\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 141.093,64.8084 158.54,57.6496\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 158.54,57.6496 159.589,49.8769\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 159.589,49.8769 160.639,42.1041\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 158.54,57.6496 173.462,69.1795\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 173.462,69.1795 179.356,66.7613\" style=\"fill:none;fill-rule:evenodd;stroke:#000000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<path d=\"M 179.356,66.7613 185.249,64.3431\" style=\"fill:none;fill-rule:evenodd;stroke:#FF0000;stroke-width:2px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\"/>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"177.678\" y=\"121.23\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"150.557\" y=\"98.1699\"><tspan>O</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"118.187\" y=\"93.7987\"><tspan>O</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"83.2939\" y=\"108.116\"><tspan>O</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"50.9243\" y=\"103.745\"><tspan>O</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#0000FF\" x=\"88.5525\" y=\"70.739\"><tspan>N</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"43.1527\" y=\"141.122\"><tspan>HO</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"72.9987\" y=\"164.182\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"107.892\" y=\"149.864\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"120.51\" y=\"56.4216\"><tspan>HO</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"155.403\" y=\"42.1041\"><tspan>OH</tspan></text>\n",
       "<text style=\"font-size:6px;font-style:normal;font-weight:normal;fill-opacity:1;stroke:none;font-family:sans-serif;text-anchor:start;fill:#FF0000\" x=\"185.249\" y=\"65.1638\"><tspan>OH</tspan></text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "mol = [Chem.MolFromSmiles(smiles)]\n",
    "SVG(Draw.MolsToGridImage(mol, molsPerRow=1, useSVG=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、選択された化合物に対して、事前に学習されたモデルを用いて水溶解度を予測していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2211]])\n"
     ]
    }
   ],
   "source": [
    "# Pop the node features\n",
    "feats = g.ndata.pop('h')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    label_pred = model(g, feats)\n",
    "\n",
    "# Mask non-existing labels\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Train your own model on a CSV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 実際に分子特性予測を行う場合、皆さんがそれぞれお持ちのカスタムデータセットを使ったモデルの作成を検討されると思います。\n",
    "- DGL-LifeSciには、学習に使いたいデータ（CSVファイル）で用意していただければ、コマンドライン一行でモデルの学習 / 推論ができるプログラムが用意されています。\n",
    "- 本節ではDGL-LifeSciが提供するプログラムを用いて化合物の水溶解度を予測するモデルの学習・推論を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本ハンズオンでは、化合物の水溶解度に関するCSVデータとして、1.1でも使用したESOLデータセットを使用します。もしお手持ちのデータでモデルの学習ないし推論を試したい場合は、以下で説明する形式のCSVファイルを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a CSV Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずは対象データをCSV形式で準備する必要があります。ESOLデータセットをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ESOL.zip from https://data.dgl.ai/dataset/ESOL.zip...\n",
      "Extracting file to ./ESOL\n"
     ]
    }
   ],
   "source": [
    "from dgl.data.utils import download, _get_dgl_url, extract_archive\n",
    "\n",
    "url = 'dataset/ESOL.zip'\n",
    "data_path = 'ESOL.zip'\n",
    "download(_get_dgl_url(url), path=data_path)\n",
    "extract_archive(data_path, './ESOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound ID</th>\n",
       "      <th>ESOL predicted log solubility in mols per litre</th>\n",
       "      <th>Minimum Degree</th>\n",
       "      <th>Molecular Weight</th>\n",
       "      <th>Number of H-Bond Donors</th>\n",
       "      <th>Number of Rings</th>\n",
       "      <th>Number of Rotatable Bonds</th>\n",
       "      <th>Polar Surface Area</th>\n",
       "      <th>measured log solubility in mols per litre</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amigdalin</td>\n",
       "      <td>-0.974</td>\n",
       "      <td>1</td>\n",
       "      <td>457.432</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>202.32</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fenfuram</td>\n",
       "      <td>-2.885</td>\n",
       "      <td>1</td>\n",
       "      <td>201.225</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>42.24</td>\n",
       "      <td>-3.30</td>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>citral</td>\n",
       "      <td>-2.579</td>\n",
       "      <td>1</td>\n",
       "      <td>152.237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>17.07</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Picene</td>\n",
       "      <td>-6.618</td>\n",
       "      <td>2</td>\n",
       "      <td>278.354</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.87</td>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thiophene</td>\n",
       "      <td>-2.232</td>\n",
       "      <td>2</td>\n",
       "      <td>84.143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>c1ccsc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benzothiazole</td>\n",
       "      <td>-2.733</td>\n",
       "      <td>2</td>\n",
       "      <td>135.191</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12.89</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>c2ccc1scnc1c2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2,2,4,6,6'-PCB</td>\n",
       "      <td>-6.545</td>\n",
       "      <td>1</td>\n",
       "      <td>326.437</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-7.32</td>\n",
       "      <td>Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Estradiol</td>\n",
       "      <td>-4.138</td>\n",
       "      <td>1</td>\n",
       "      <td>272.388</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>40.46</td>\n",
       "      <td>-5.03</td>\n",
       "      <td>CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dieldrin</td>\n",
       "      <td>-4.533</td>\n",
       "      <td>1</td>\n",
       "      <td>380.913</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12.53</td>\n",
       "      <td>-6.29</td>\n",
       "      <td>ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rotenone</td>\n",
       "      <td>-5.246</td>\n",
       "      <td>1</td>\n",
       "      <td>394.423</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>63.22</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Compound ID  ESOL predicted log solubility in mols per litre  \\\n",
       "0       Amigdalin                                           -0.974   \n",
       "1        Fenfuram                                           -2.885   \n",
       "2          citral                                           -2.579   \n",
       "3          Picene                                           -6.618   \n",
       "4       Thiophene                                           -2.232   \n",
       "5   benzothiazole                                           -2.733   \n",
       "6  2,2,4,6,6'-PCB                                           -6.545   \n",
       "7       Estradiol                                           -4.138   \n",
       "8        Dieldrin                                           -4.533   \n",
       "9        Rotenone                                           -5.246   \n",
       "\n",
       "   Minimum Degree  Molecular Weight  Number of H-Bond Donors  Number of Rings  \\\n",
       "0               1           457.432                        7                3   \n",
       "1               1           201.225                        1                2   \n",
       "2               1           152.237                        0                0   \n",
       "3               2           278.354                        0                5   \n",
       "4               2            84.143                        0                1   \n",
       "5               2           135.191                        0                2   \n",
       "6               1           326.437                        0                2   \n",
       "7               1           272.388                        2                4   \n",
       "8               1           380.913                        0                5   \n",
       "9               1           394.423                        0                5   \n",
       "\n",
       "   Number of Rotatable Bonds  Polar Surface Area  \\\n",
       "0                          7              202.32   \n",
       "1                          2               42.24   \n",
       "2                          4               17.07   \n",
       "3                          0                0.00   \n",
       "4                          0                0.00   \n",
       "5                          0               12.89   \n",
       "6                          1                0.00   \n",
       "7                          0               40.46   \n",
       "8                          0               12.53   \n",
       "9                          3               63.22   \n",
       "\n",
       "   measured log solubility in mols per litre  \\\n",
       "0                                      -0.77   \n",
       "1                                      -3.30   \n",
       "2                                      -2.06   \n",
       "3                                      -7.87   \n",
       "4                                      -1.33   \n",
       "5                                      -1.50   \n",
       "6                                      -7.32   \n",
       "7                                      -5.03   \n",
       "8                                      -6.29   \n",
       "9                                      -4.42   \n",
       "\n",
       "                                              smiles  \n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...  \n",
       "1                             Cc1occc1C(=O)Nc2ccccc2  \n",
       "2                               CC(C)=CCCC(C)=CC(=O)  \n",
       "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43  \n",
       "4                                            c1ccsc1  \n",
       "5                                     c2ccc1scnc1c2   \n",
       "6                 Clc1cc(Cl)c(c(Cl)c1)c2c(Cl)cccc2Cl  \n",
       "7                   CC12CCC3C(CCc4cc(O)ccc34)C2CCC1O  \n",
       "8     ClC4=C(Cl)C5(Cl)C3C1CC(C2OC12)C3C4(Cl)C5(Cl)Cl  \n",
       "9   COc5cc4OCC3Oc2c1CC(Oc1ccc2C(=O)C3c4cc5OC)C(C)=C   "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('ESOL/delaney-processed.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータは上のようになっています。\n",
    "複数あるカラムのうち、今回予測対象となる水溶解度は`measured log solubility in mols per litre`であり、`smiles`カラムが入力となるSMILES文字列となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download sample scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コマンドラインで実行できるプログラムはDGL-LifeSciの公式リポジトリにあります。まず、リポジトリをクローンします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dgl-lifesci'...\n",
      "remote: Enumerating objects: 3145, done.\u001b[K\n",
      "remote: Counting objects: 100% (347/347), done.\u001b[K\n",
      "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
      "remote: Total 3145 (delta 166), reused 282 (delta 133), pack-reused 2798\u001b[K\n",
      "Receiving objects: 100% (3145/3145), 978.19 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (1907/1907), done.\n",
      "Checking connectivity... done.\n",
      "Checking out files: 100% (406/406), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/awslabs/dgl-lifesci.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Yusmoris-dgllifesci-handson\n",
      "\u001b[0m\u001b[01;34mESOL\u001b[0m/                               \u001b[01;34manalysis_results\u001b[0m/\n",
      "ESOL.zip                            \u001b[01;34mcsv_data_configuration\u001b[0m/\n",
      "GCN_Tox21_pre_trained.pth           \u001b[01;34mdgl-lifesci\u001b[0m/\n",
      "GCN_canonical_ESOL_pre_trained.pth  esol_dglgraph.bin\n",
      "PropertyPrediction-ESOL.ipynb       \u001b[01;34mregression_results\u001b[0m/\n",
      "PropertyPrediction.ipynb            tox21_dglgraph.bin\n"
     ]
    }
   ],
   "source": [
    "%cp ./dgl-lifesci/examples/property_prediction/csv_data_configuration/ -r ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まずはデータセットについて分析してみましょう。化合物について簡単に分析するためのスクリプトが用意されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Directory ./analysis_results already exists.\n"
     ]
    }
   ],
   "source": [
    "!python ./csv_data_configuration/analysis.py -c ./ESOL/delaney-processed.csv -sc 'smiles' -p ./analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General statistics\n",
      "============================================================\n",
      "Number of input molecules: 1128\n",
      "Number of valid molecules: 1128\n",
      "Percentage of valid molecules: 100.0 %\n",
      "Average number of atoms per molecule: 13.289893617021276 +- 6.875553155518211\n",
      "Average number of bonds per molecule: 13.677304964539006 +- 7.922527077263628\n",
      "Average number of rings per molecule: 1.3909574468085106 +- 1.3177012832763317\n",
      "\n",
      "Atom statistics\n",
      "============================================================\n",
      "atom_type frequency: {'O': 725, 'C': 1128, 'N': 457, 'S': 116, 'Cl': 252, 'P': 43, 'F': 44, 'I': 16, 'Br': 50}\n",
      "degree frequency: {1: 1060, 2: 1071, 3: 963, 4: 281, 0: 1}\n",
      "total_degree frequency: {1: 740, 2: 621, 3: 912, 4: 884}\n",
      "explicit_valence frequency: {1: 1018, 2: 844, 3: 934, 4: 920, 5: 43, 6: 25, 0: 1}\n",
      "implicit_valence frequency: {0: 1017, 1: 966, 2: 660, 3: 728, 4: 1}\n",
      "hybridization frequency: {'SP2': 920, 'SP3': 1010, 'SP': 39}\n",
      "total_num_h frequency: {0: 1017, 1: 968, 2: 660, 3: 728, 4: 1}\n",
      "formal_charge frequency: {0: 1128, 1: 59, -1: 59}\n",
      "num_radical_electrons frequency: {0: 1128}\n",
      "aromatic_atom frequency: {False: 1088, True: 662}\n",
      "chirality_tag frequency: {'CHI_UNSPECIFIED': 1128}\n",
      "\n",
      "Bond statistics\n",
      "============================================================\n",
      "bond_type frequency: {'TRIPLE': 39, 'SINGLE': 1088, 'AROMATIC': 662, 'DOUBLE': 594}\n",
      "conjugated_bond frequency: {False: 1012, True: 837}\n",
      "bond_stereo_configuration frequency: {'STEREONONE': 1127, 'STEREOE': 3, 'STEREOZ': 3}\n",
      "bond_direction frequency: {'NONE': 1127, 'ENDUPRIGHT': 8, 'ENDDOWNRIGHT': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./analysis_results/summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Yusmoris-dgllifesci-handson/csv_data_configuration\n",
      "Using backend: pytorch\n",
      "Directory ../regression_results already exists.\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/1128\n",
      "Start initializing RDKit molecule instances...\n",
      "Creating RDKit molecule instance 1000/1128\n",
      "Start computing Bemis-Murcko scaffolds.\n",
      "Computing Bemis-Murcko for compound 1000/1128\n",
      "Use the manually specified hyperparameters\n",
      "Created directory ../regression_results/28\n",
      "For metric rmse, the lower the better\n",
      "[2022-12-14 10:07:10.660 pytorch-1-6-cpu-py36--ml-t3-medium-e161cdcbc257f26c3e80f094dd8d:25160 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-12-14 10:07:10.736 pytorch-1-6-cpu-py36--ml-t3-medium-e161cdcbc257f26c3e80f094dd8d:25160 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "epoch 1/1000, batch 1/8, loss 2.7887\n",
      "epoch 1/1000, training rmse 2.9970\n",
      "epoch 1/1000, validation rmse 11.9685, best validation rmse 11.9685\n",
      "epoch 2/1000, batch 1/8, loss 1.0282\n",
      "epoch 2/1000, training rmse 1.6489\n",
      "epoch 2/1000, validation rmse 4.8760, best validation rmse 4.8760\n",
      "epoch 3/1000, batch 1/8, loss 0.8655\n",
      "epoch 3/1000, training rmse 1.3793\n",
      "epoch 3/1000, validation rmse 2.1342, best validation rmse 2.1342\n",
      "epoch 4/1000, batch 1/8, loss 0.6279\n",
      "epoch 4/1000, training rmse 1.3578\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 4/1000, validation rmse 4.5619, best validation rmse 2.1342\n",
      "epoch 5/1000, batch 1/8, loss 0.5054\n",
      "epoch 5/1000, training rmse 1.1081\n",
      "epoch 5/1000, validation rmse 1.7723, best validation rmse 1.7723\n",
      "epoch 6/1000, batch 1/8, loss 0.4210\n",
      "epoch 6/1000, training rmse 1.0151\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 6/1000, validation rmse 3.5397, best validation rmse 1.7723\n",
      "epoch 7/1000, batch 1/8, loss 0.5016\n",
      "epoch 7/1000, training rmse 1.0420\n",
      "epoch 7/1000, validation rmse 1.4174, best validation rmse 1.4174\n",
      "epoch 8/1000, batch 1/8, loss 0.3735\n",
      "epoch 8/1000, training rmse 0.9902\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 8/1000, validation rmse 1.8544, best validation rmse 1.4174\n",
      "epoch 9/1000, batch 1/8, loss 0.5390\n",
      "epoch 9/1000, training rmse 1.0191\n",
      "epoch 9/1000, validation rmse 1.3139, best validation rmse 1.3139\n",
      "epoch 10/1000, batch 1/8, loss 0.3698\n",
      "epoch 10/1000, training rmse 0.9085\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 10/1000, validation rmse 239.2283, best validation rmse 1.3139\n",
      "epoch 11/1000, batch 1/8, loss 0.3256\n",
      "epoch 11/1000, training rmse 0.9289\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 11/1000, validation rmse 1.3405, best validation rmse 1.3139\n",
      "epoch 12/1000, batch 1/8, loss 0.2462\n",
      "epoch 12/1000, training rmse 0.8048\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 12/1000, validation rmse 1.3376, best validation rmse 1.3139\n",
      "epoch 13/1000, batch 1/8, loss 0.3140\n",
      "epoch 13/1000, training rmse 0.7784\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 13/1000, validation rmse 40.6521, best validation rmse 1.3139\n",
      "epoch 14/1000, batch 1/8, loss 0.2580\n",
      "epoch 14/1000, training rmse 0.7708\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 14/1000, validation rmse 1.3444, best validation rmse 1.3139\n",
      "epoch 15/1000, batch 1/8, loss 0.2860\n",
      "epoch 15/1000, training rmse 0.8234\n",
      "epoch 15/1000, validation rmse 1.1546, best validation rmse 1.1546\n",
      "epoch 16/1000, batch 1/8, loss 0.2169\n",
      "epoch 16/1000, training rmse 0.7779\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 16/1000, validation rmse 1.2589, best validation rmse 1.1546\n",
      "epoch 17/1000, batch 1/8, loss 0.2191\n",
      "epoch 17/1000, training rmse 0.8309\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 17/1000, validation rmse 1.3431, best validation rmse 1.1546\n",
      "epoch 18/1000, batch 1/8, loss 0.2232\n",
      "epoch 18/1000, training rmse 0.7369\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 18/1000, validation rmse 1.3152, best validation rmse 1.1546\n",
      "epoch 19/1000, batch 1/8, loss 0.2122\n",
      "epoch 19/1000, training rmse 0.8298\n",
      "epoch 19/1000, validation rmse 1.1195, best validation rmse 1.1195\n",
      "epoch 20/1000, batch 1/8, loss 0.2170\n",
      "epoch 20/1000, training rmse 0.7336\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 20/1000, validation rmse 1.1399, best validation rmse 1.1195\n",
      "epoch 21/1000, batch 1/8, loss 0.1881\n",
      "epoch 21/1000, training rmse 0.7725\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 21/1000, validation rmse 2.0765, best validation rmse 1.1195\n",
      "epoch 22/1000, batch 1/8, loss 0.3251\n",
      "epoch 22/1000, training rmse 0.8966\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 22/1000, validation rmse 1.5972, best validation rmse 1.1195\n",
      "epoch 23/1000, batch 1/8, loss 0.4015\n",
      "epoch 23/1000, training rmse 0.9222\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 23/1000, validation rmse 1.2450, best validation rmse 1.1195\n",
      "epoch 24/1000, batch 1/8, loss 0.1886\n",
      "epoch 24/1000, training rmse 0.8853\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 24/1000, validation rmse 1.1296, best validation rmse 1.1195\n",
      "epoch 25/1000, batch 1/8, loss 0.2313\n",
      "epoch 25/1000, training rmse 0.8659\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 25/1000, validation rmse 1.3342, best validation rmse 1.1195\n",
      "epoch 26/1000, batch 1/8, loss 0.3875\n",
      "epoch 26/1000, training rmse 0.8187\n",
      "epoch 26/1000, validation rmse 1.0844, best validation rmse 1.0844\n",
      "epoch 27/1000, batch 1/8, loss 0.2972\n",
      "epoch 27/1000, training rmse 0.7507\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 27/1000, validation rmse 1.1783, best validation rmse 1.0844\n",
      "epoch 28/1000, batch 1/8, loss 0.1672\n",
      "epoch 28/1000, training rmse 0.7498\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 28/1000, validation rmse 1.2142, best validation rmse 1.0844\n",
      "epoch 29/1000, batch 1/8, loss 0.1702\n",
      "epoch 29/1000, training rmse 0.6956\n",
      "epoch 29/1000, validation rmse 1.0547, best validation rmse 1.0547\n",
      "epoch 30/1000, batch 1/8, loss 0.2736\n",
      "epoch 30/1000, training rmse 0.8258\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 30/1000, validation rmse 1.1617, best validation rmse 1.0547\n",
      "epoch 31/1000, batch 1/8, loss 0.2866\n",
      "epoch 31/1000, training rmse 0.7658\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 31/1000, validation rmse 1.6693, best validation rmse 1.0547\n",
      "epoch 32/1000, batch 1/8, loss 0.1655\n",
      "epoch 32/1000, training rmse 0.7564\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 32/1000, validation rmse 1.2475, best validation rmse 1.0547\n",
      "epoch 33/1000, batch 1/8, loss 0.1823\n",
      "epoch 33/1000, training rmse 0.7168\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 33/1000, validation rmse 1.2773, best validation rmse 1.0547\n",
      "epoch 34/1000, batch 1/8, loss 0.2640\n",
      "epoch 34/1000, training rmse 0.7780\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 34/1000, validation rmse 1.1446, best validation rmse 1.0547\n",
      "epoch 35/1000, batch 1/8, loss 0.1691\n",
      "epoch 35/1000, training rmse 0.7191\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 35/1000, validation rmse 1.8723, best validation rmse 1.0547\n",
      "epoch 36/1000, batch 1/8, loss 0.1895\n",
      "epoch 36/1000, training rmse 0.7459\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 36/1000, validation rmse 1.0796, best validation rmse 1.0547\n",
      "epoch 37/1000, batch 1/8, loss 0.2652\n",
      "epoch 37/1000, training rmse 0.7856\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 37/1000, validation rmse 1.1362, best validation rmse 1.0547\n",
      "epoch 38/1000, batch 1/8, loss 0.1708\n",
      "epoch 38/1000, training rmse 0.7730\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 38/1000, validation rmse 1.3094, best validation rmse 1.0547\n",
      "epoch 39/1000, batch 1/8, loss 0.1743\n",
      "epoch 39/1000, training rmse 0.6874\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 39/1000, validation rmse 1.0893, best validation rmse 1.0547\n",
      "epoch 40/1000, batch 1/8, loss 0.1278\n",
      "epoch 40/1000, training rmse 0.6969\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 40/1000, validation rmse 1.2986, best validation rmse 1.0547\n",
      "epoch 41/1000, batch 1/8, loss 0.2461\n",
      "epoch 41/1000, training rmse 0.7718\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 41/1000, validation rmse 1.3592, best validation rmse 1.0547\n",
      "epoch 42/1000, batch 1/8, loss 0.2796\n",
      "epoch 42/1000, training rmse 0.8324\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 42/1000, validation rmse 1.5625, best validation rmse 1.0547\n",
      "epoch 43/1000, batch 1/8, loss 0.2699\n",
      "epoch 43/1000, training rmse 0.7031\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 43/1000, validation rmse 1.1053, best validation rmse 1.0547\n",
      "epoch 44/1000, batch 1/8, loss 0.3179\n",
      "epoch 44/1000, training rmse 0.7756\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 44/1000, validation rmse 1.0688, best validation rmse 1.0547\n",
      "epoch 45/1000, batch 1/8, loss 0.1812\n",
      "epoch 45/1000, training rmse 0.7632\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 45/1000, validation rmse 1.2033, best validation rmse 1.0547\n",
      "epoch 46/1000, batch 1/8, loss 0.2228\n",
      "epoch 46/1000, training rmse 0.6992\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 46/1000, validation rmse 1.3629, best validation rmse 1.0547\n",
      "epoch 47/1000, batch 1/8, loss 0.1638\n",
      "epoch 47/1000, training rmse 0.6961\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 47/1000, validation rmse 1.1874, best validation rmse 1.0547\n",
      "epoch 48/1000, batch 1/8, loss 0.2053\n",
      "epoch 48/1000, training rmse 0.7107\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 48/1000, validation rmse 1.1036, best validation rmse 1.0547\n",
      "epoch 49/1000, batch 1/8, loss 0.1740\n",
      "epoch 49/1000, training rmse 0.6914\n",
      "EarlyStopping counter: 20 out of 30\n",
      "epoch 49/1000, validation rmse 1.2398, best validation rmse 1.0547\n",
      "epoch 50/1000, batch 1/8, loss 0.3687\n",
      "epoch 50/1000, training rmse 0.7097\n",
      "EarlyStopping counter: 21 out of 30\n",
      "epoch 50/1000, validation rmse 1.2394, best validation rmse 1.0547\n",
      "epoch 51/1000, batch 1/8, loss 0.1895\n",
      "epoch 51/1000, training rmse 0.7198\n",
      "EarlyStopping counter: 22 out of 30\n",
      "epoch 51/1000, validation rmse 1.1498, best validation rmse 1.0547\n",
      "epoch 52/1000, batch 1/8, loss 0.2106\n",
      "epoch 52/1000, training rmse 0.7020\n",
      "EarlyStopping counter: 23 out of 30\n",
      "epoch 52/1000, validation rmse 1.1700, best validation rmse 1.0547\n",
      "epoch 53/1000, batch 1/8, loss 0.1497\n",
      "epoch 53/1000, training rmse 0.6056\n",
      "EarlyStopping counter: 24 out of 30\n",
      "epoch 53/1000, validation rmse 1.0849, best validation rmse 1.0547\n",
      "epoch 54/1000, batch 1/8, loss 0.1528\n",
      "epoch 54/1000, training rmse 0.6982\n",
      "EarlyStopping counter: 25 out of 30\n",
      "epoch 54/1000, validation rmse 1.0873, best validation rmse 1.0547\n",
      "epoch 55/1000, batch 1/8, loss 0.1896\n",
      "epoch 55/1000, training rmse 0.6785\n",
      "EarlyStopping counter: 26 out of 30\n",
      "epoch 55/1000, validation rmse 1.1152, best validation rmse 1.0547\n",
      "epoch 56/1000, batch 1/8, loss 0.1625\n",
      "epoch 56/1000, training rmse 0.6639\n",
      "epoch 56/1000, validation rmse 1.0143, best validation rmse 1.0143\n",
      "epoch 57/1000, batch 1/8, loss 0.1683\n",
      "epoch 57/1000, training rmse 0.7220\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 57/1000, validation rmse 1.2703, best validation rmse 1.0143\n",
      "epoch 58/1000, batch 1/8, loss 0.1304\n",
      "epoch 58/1000, training rmse 0.6959\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 58/1000, validation rmse 1.1003, best validation rmse 1.0143\n",
      "epoch 59/1000, batch 1/8, loss 0.1568\n",
      "epoch 59/1000, training rmse 0.6345\n",
      "epoch 59/1000, validation rmse 1.0012, best validation rmse 1.0012\n",
      "epoch 60/1000, batch 1/8, loss 0.2297\n",
      "epoch 60/1000, training rmse 0.6755\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 60/1000, validation rmse 1.1485, best validation rmse 1.0012\n",
      "epoch 61/1000, batch 1/8, loss 0.1779\n",
      "epoch 61/1000, training rmse 0.7579\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 61/1000, validation rmse 1.1564, best validation rmse 1.0012\n",
      "epoch 62/1000, batch 1/8, loss 0.2016\n",
      "epoch 62/1000, training rmse 0.6934\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 62/1000, validation rmse 1.0631, best validation rmse 1.0012\n",
      "epoch 63/1000, batch 1/8, loss 0.1317\n",
      "epoch 63/1000, training rmse 0.6507\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 63/1000, validation rmse 1.4269, best validation rmse 1.0012\n",
      "epoch 64/1000, batch 1/8, loss 0.3278\n",
      "epoch 64/1000, training rmse 0.7295\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 64/1000, validation rmse 1.0650, best validation rmse 1.0012\n",
      "epoch 65/1000, batch 1/8, loss 0.1951\n",
      "epoch 65/1000, training rmse 0.6470\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 65/1000, validation rmse 1.1281, best validation rmse 1.0012\n",
      "epoch 66/1000, batch 1/8, loss 0.1418\n",
      "epoch 66/1000, training rmse 0.6119\n",
      "epoch 66/1000, validation rmse 0.9790, best validation rmse 0.9790\n",
      "epoch 67/1000, batch 1/8, loss 0.1556\n",
      "epoch 67/1000, training rmse 0.6267\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 67/1000, validation rmse 1.0777, best validation rmse 0.9790\n",
      "epoch 68/1000, batch 1/8, loss 0.2043\n",
      "epoch 68/1000, training rmse 0.6763\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 68/1000, validation rmse 1.2579, best validation rmse 0.9790\n",
      "epoch 69/1000, batch 1/8, loss 0.1962\n",
      "epoch 69/1000, training rmse 0.7037\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 69/1000, validation rmse 1.3069, best validation rmse 0.9790\n",
      "epoch 70/1000, batch 1/8, loss 0.1595\n",
      "epoch 70/1000, training rmse 0.6611\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 70/1000, validation rmse 1.0695, best validation rmse 0.9790\n",
      "epoch 71/1000, batch 1/8, loss 0.1344\n",
      "epoch 71/1000, training rmse 0.5844\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 71/1000, validation rmse 1.1554, best validation rmse 0.9790\n",
      "epoch 72/1000, batch 1/8, loss 0.1277\n",
      "epoch 72/1000, training rmse 0.6146\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 72/1000, validation rmse 1.0449, best validation rmse 0.9790\n",
      "epoch 73/1000, batch 1/8, loss 0.1679\n",
      "epoch 73/1000, training rmse 0.5875\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 73/1000, validation rmse 1.1023, best validation rmse 0.9790\n",
      "epoch 74/1000, batch 1/8, loss 0.1361\n",
      "epoch 74/1000, training rmse 0.6350\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 74/1000, validation rmse 1.0931, best validation rmse 0.9790\n",
      "epoch 75/1000, batch 1/8, loss 0.1451\n",
      "epoch 75/1000, training rmse 0.6109\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 75/1000, validation rmse 0.9871, best validation rmse 0.9790\n",
      "epoch 76/1000, batch 1/8, loss 0.1656\n",
      "epoch 76/1000, training rmse 0.6822\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 76/1000, validation rmse 1.0485, best validation rmse 0.9790\n",
      "epoch 77/1000, batch 1/8, loss 0.1606\n",
      "epoch 77/1000, training rmse 0.6240\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 77/1000, validation rmse 1.0199, best validation rmse 0.9790\n",
      "epoch 78/1000, batch 1/8, loss 0.1661\n",
      "epoch 78/1000, training rmse 0.6240\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 78/1000, validation rmse 1.0741, best validation rmse 0.9790\n",
      "epoch 79/1000, batch 1/8, loss 0.1444\n",
      "epoch 79/1000, training rmse 0.6404\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 79/1000, validation rmse 1.2924, best validation rmse 0.9790\n",
      "epoch 80/1000, batch 1/8, loss 0.0978\n",
      "epoch 80/1000, training rmse 0.6600\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 80/1000, validation rmse 1.1898, best validation rmse 0.9790\n",
      "epoch 81/1000, batch 1/8, loss 0.2465\n",
      "epoch 81/1000, training rmse 0.6665\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 81/1000, validation rmse 1.6759, best validation rmse 0.9790\n",
      "epoch 82/1000, batch 1/8, loss 0.1562\n",
      "epoch 82/1000, training rmse 0.6530\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 82/1000, validation rmse 1.1108, best validation rmse 0.9790\n",
      "epoch 83/1000, batch 1/8, loss 0.1966\n",
      "epoch 83/1000, training rmse 0.6770\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 83/1000, validation rmse 0.9988, best validation rmse 0.9790\n",
      "epoch 84/1000, batch 1/8, loss 0.2081\n",
      "epoch 84/1000, training rmse 0.6348\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 84/1000, validation rmse 1.0207, best validation rmse 0.9790\n",
      "epoch 85/1000, batch 1/8, loss 0.1584\n",
      "epoch 85/1000, training rmse 0.6392\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 85/1000, validation rmse 1.1513, best validation rmse 0.9790\n",
      "epoch 86/1000, batch 1/8, loss 0.1020\n",
      "epoch 86/1000, training rmse 0.6203\n",
      "EarlyStopping counter: 20 out of 30\n",
      "epoch 86/1000, validation rmse 0.9805, best validation rmse 0.9790\n",
      "epoch 87/1000, batch 1/8, loss 0.1236\n",
      "epoch 87/1000, training rmse 0.6996\n",
      "EarlyStopping counter: 21 out of 30\n",
      "epoch 87/1000, validation rmse 1.0027, best validation rmse 0.9790\n",
      "epoch 88/1000, batch 1/8, loss 0.1578\n",
      "epoch 88/1000, training rmse 0.5746\n",
      "EarlyStopping counter: 22 out of 30\n",
      "epoch 88/1000, validation rmse 1.1032, best validation rmse 0.9790\n",
      "epoch 89/1000, batch 1/8, loss 0.1535\n",
      "epoch 89/1000, training rmse 0.6514\n",
      "EarlyStopping counter: 23 out of 30\n",
      "epoch 89/1000, validation rmse 1.0633, best validation rmse 0.9790\n",
      "epoch 90/1000, batch 1/8, loss 0.1467\n",
      "epoch 90/1000, training rmse 0.6481\n",
      "epoch 90/1000, validation rmse 0.9622, best validation rmse 0.9622\n",
      "epoch 91/1000, batch 1/8, loss 0.1792\n",
      "epoch 91/1000, training rmse 0.6512\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 91/1000, validation rmse 1.1121, best validation rmse 0.9622\n",
      "epoch 92/1000, batch 1/8, loss 0.1637\n",
      "epoch 92/1000, training rmse 0.6028\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 92/1000, validation rmse 0.9788, best validation rmse 0.9622\n",
      "epoch 93/1000, batch 1/8, loss 0.1803\n",
      "epoch 93/1000, training rmse 0.6023\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 93/1000, validation rmse 1.0226, best validation rmse 0.9622\n",
      "epoch 94/1000, batch 1/8, loss 0.1245\n",
      "epoch 94/1000, training rmse 0.6459\n",
      "epoch 94/1000, validation rmse 0.9518, best validation rmse 0.9518\n",
      "epoch 95/1000, batch 1/8, loss 0.1434\n",
      "epoch 95/1000, training rmse 0.5777\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 95/1000, validation rmse 0.9543, best validation rmse 0.9518\n",
      "epoch 96/1000, batch 1/8, loss 0.1817\n",
      "epoch 96/1000, training rmse 0.6150\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 96/1000, validation rmse 0.9688, best validation rmse 0.9518\n",
      "epoch 97/1000, batch 1/8, loss 0.1285\n",
      "epoch 97/1000, training rmse 0.5761\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 97/1000, validation rmse 0.9673, best validation rmse 0.9518\n",
      "epoch 98/1000, batch 1/8, loss 0.1656\n",
      "epoch 98/1000, training rmse 0.5781\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 98/1000, validation rmse 0.9704, best validation rmse 0.9518\n",
      "epoch 99/1000, batch 1/8, loss 0.0950\n",
      "epoch 99/1000, training rmse 0.5239\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 99/1000, validation rmse 0.9898, best validation rmse 0.9518\n",
      "epoch 100/1000, batch 1/8, loss 0.1471\n",
      "epoch 100/1000, training rmse 0.5909\n",
      "epoch 100/1000, validation rmse 0.9422, best validation rmse 0.9422\n",
      "epoch 101/1000, batch 1/8, loss 0.2151\n",
      "epoch 101/1000, training rmse 0.6177\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 101/1000, validation rmse 1.1041, best validation rmse 0.9422\n",
      "epoch 102/1000, batch 1/8, loss 0.1617\n",
      "epoch 102/1000, training rmse 0.6469\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 102/1000, validation rmse 0.9555, best validation rmse 0.9422\n",
      "epoch 103/1000, batch 1/8, loss 0.0883\n",
      "epoch 103/1000, training rmse 0.6366\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 103/1000, validation rmse 0.9772, best validation rmse 0.9422\n",
      "epoch 104/1000, batch 1/8, loss 0.1029\n",
      "epoch 104/1000, training rmse 0.5686\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 104/1000, validation rmse 1.0176, best validation rmse 0.9422\n",
      "epoch 105/1000, batch 1/8, loss 0.1166\n",
      "epoch 105/1000, training rmse 0.5589\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 105/1000, validation rmse 0.9903, best validation rmse 0.9422\n",
      "epoch 106/1000, batch 1/8, loss 0.1556\n",
      "epoch 106/1000, training rmse 0.5809\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 106/1000, validation rmse 1.0937, best validation rmse 0.9422\n",
      "epoch 107/1000, batch 1/8, loss 0.1984\n",
      "epoch 107/1000, training rmse 0.5491\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 107/1000, validation rmse 1.0377, best validation rmse 0.9422\n",
      "epoch 108/1000, batch 1/8, loss 0.1570\n",
      "epoch 108/1000, training rmse 0.5532\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 108/1000, validation rmse 1.0803, best validation rmse 0.9422\n",
      "epoch 109/1000, batch 1/8, loss 0.1335\n",
      "epoch 109/1000, training rmse 0.5698\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 109/1000, validation rmse 1.1051, best validation rmse 0.9422\n",
      "epoch 110/1000, batch 1/8, loss 0.1467\n",
      "epoch 110/1000, training rmse 0.6052\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 110/1000, validation rmse 1.0708, best validation rmse 0.9422\n",
      "epoch 111/1000, batch 1/8, loss 0.2461\n",
      "epoch 111/1000, training rmse 0.6090\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 111/1000, validation rmse 1.0655, best validation rmse 0.9422\n",
      "epoch 112/1000, batch 1/8, loss 0.1824\n",
      "epoch 112/1000, training rmse 0.5829\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 112/1000, validation rmse 0.9936, best validation rmse 0.9422\n",
      "epoch 113/1000, batch 1/8, loss 0.1364\n",
      "epoch 113/1000, training rmse 0.6444\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 113/1000, validation rmse 1.0258, best validation rmse 0.9422\n",
      "epoch 114/1000, batch 1/8, loss 0.0849\n",
      "epoch 114/1000, training rmse 0.5695\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 114/1000, validation rmse 0.9544, best validation rmse 0.9422\n",
      "epoch 115/1000, batch 1/8, loss 0.1179\n",
      "epoch 115/1000, training rmse 0.6029\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 115/1000, validation rmse 1.0093, best validation rmse 0.9422\n",
      "epoch 116/1000, batch 1/8, loss 0.1244\n",
      "epoch 116/1000, training rmse 0.5862\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 116/1000, validation rmse 0.9627, best validation rmse 0.9422\n",
      "epoch 117/1000, batch 1/8, loss 0.1322\n",
      "epoch 117/1000, training rmse 0.6284\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 117/1000, validation rmse 1.0561, best validation rmse 0.9422\n",
      "epoch 118/1000, batch 1/8, loss 0.1165\n",
      "epoch 118/1000, training rmse 0.7096\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 118/1000, validation rmse 0.9490, best validation rmse 0.9422\n",
      "epoch 119/1000, batch 1/8, loss 0.1227\n",
      "epoch 119/1000, training rmse 0.8209\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 119/1000, validation rmse 1.1357, best validation rmse 0.9422\n",
      "epoch 120/1000, batch 1/8, loss 0.1428\n",
      "epoch 120/1000, training rmse 0.5366\n",
      "EarlyStopping counter: 20 out of 30\n",
      "epoch 120/1000, validation rmse 0.9769, best validation rmse 0.9422\n",
      "epoch 121/1000, batch 1/8, loss 0.1588\n",
      "epoch 121/1000, training rmse 0.5821\n",
      "EarlyStopping counter: 21 out of 30\n",
      "epoch 121/1000, validation rmse 0.9950, best validation rmse 0.9422\n",
      "epoch 122/1000, batch 1/8, loss 0.1553\n",
      "epoch 122/1000, training rmse 0.5953\n",
      "EarlyStopping counter: 22 out of 30\n",
      "epoch 122/1000, validation rmse 1.0032, best validation rmse 0.9422\n",
      "epoch 123/1000, batch 1/8, loss 0.1607\n",
      "epoch 123/1000, training rmse 0.5875\n",
      "EarlyStopping counter: 23 out of 30\n",
      "epoch 123/1000, validation rmse 1.0934, best validation rmse 0.9422\n",
      "epoch 124/1000, batch 1/8, loss 0.1070\n",
      "epoch 124/1000, training rmse 0.6733\n",
      "EarlyStopping counter: 24 out of 30\n",
      "epoch 124/1000, validation rmse 0.9590, best validation rmse 0.9422\n",
      "epoch 125/1000, batch 1/8, loss 0.1778\n",
      "epoch 125/1000, training rmse 0.5616\n",
      "EarlyStopping counter: 25 out of 30\n",
      "epoch 125/1000, validation rmse 0.9500, best validation rmse 0.9422\n",
      "epoch 126/1000, batch 1/8, loss 0.1276\n",
      "epoch 126/1000, training rmse 0.5411\n",
      "epoch 126/1000, validation rmse 0.9379, best validation rmse 0.9379\n",
      "epoch 127/1000, batch 1/8, loss 0.1379\n",
      "epoch 127/1000, training rmse 0.5186\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 127/1000, validation rmse 1.1682, best validation rmse 0.9379\n",
      "epoch 128/1000, batch 1/8, loss 0.1802\n",
      "epoch 128/1000, training rmse 0.5669\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 128/1000, validation rmse 1.0141, best validation rmse 0.9379\n",
      "epoch 129/1000, batch 1/8, loss 0.1789\n",
      "epoch 129/1000, training rmse 0.5929\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 129/1000, validation rmse 0.9896, best validation rmse 0.9379\n",
      "epoch 130/1000, batch 1/8, loss 0.2391\n",
      "epoch 130/1000, training rmse 0.5994\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 130/1000, validation rmse 1.2940, best validation rmse 0.9379\n",
      "epoch 131/1000, batch 1/8, loss 0.1890\n",
      "epoch 131/1000, training rmse 0.6034\n",
      "epoch 131/1000, validation rmse 0.9325, best validation rmse 0.9325\n",
      "epoch 132/1000, batch 1/8, loss 0.1575\n",
      "epoch 132/1000, training rmse 0.5575\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 132/1000, validation rmse 1.0215, best validation rmse 0.9325\n",
      "epoch 133/1000, batch 1/8, loss 0.1143\n",
      "epoch 133/1000, training rmse 0.5724\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 133/1000, validation rmse 0.9843, best validation rmse 0.9325\n",
      "epoch 134/1000, batch 1/8, loss 0.1636\n",
      "epoch 134/1000, training rmse 0.5785\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 134/1000, validation rmse 0.9615, best validation rmse 0.9325\n",
      "epoch 135/1000, batch 1/8, loss 0.1286\n",
      "epoch 135/1000, training rmse 0.7382\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 135/1000, validation rmse 0.9979, best validation rmse 0.9325\n",
      "epoch 136/1000, batch 1/8, loss 0.1027\n",
      "epoch 136/1000, training rmse 0.6387\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 136/1000, validation rmse 1.0229, best validation rmse 0.9325\n",
      "epoch 137/1000, batch 1/8, loss 0.1397\n",
      "epoch 137/1000, training rmse 0.5958\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 137/1000, validation rmse 0.9744, best validation rmse 0.9325\n",
      "epoch 138/1000, batch 1/8, loss 0.1122\n",
      "epoch 138/1000, training rmse 0.5438\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 138/1000, validation rmse 0.9735, best validation rmse 0.9325\n",
      "epoch 139/1000, batch 1/8, loss 0.1062\n",
      "epoch 139/1000, training rmse 0.5915\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 139/1000, validation rmse 1.0136, best validation rmse 0.9325\n",
      "epoch 140/1000, batch 1/8, loss 0.1458\n",
      "epoch 140/1000, training rmse 0.6920\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 140/1000, validation rmse 0.9671, best validation rmse 0.9325\n",
      "epoch 141/1000, batch 1/8, loss 0.1425\n",
      "epoch 141/1000, training rmse 0.5898\n",
      "epoch 141/1000, validation rmse 0.9224, best validation rmse 0.9224\n",
      "epoch 142/1000, batch 1/8, loss 0.0916\n",
      "epoch 142/1000, training rmse 0.5958\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 142/1000, validation rmse 1.1712, best validation rmse 0.9224\n",
      "epoch 143/1000, batch 1/8, loss 0.1527\n",
      "epoch 143/1000, training rmse 0.6184\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 143/1000, validation rmse 0.9389, best validation rmse 0.9224\n",
      "epoch 144/1000, batch 1/8, loss 0.1061\n",
      "epoch 144/1000, training rmse 0.5048\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 144/1000, validation rmse 1.0108, best validation rmse 0.9224\n",
      "epoch 145/1000, batch 1/8, loss 0.1069\n",
      "epoch 145/1000, training rmse 0.4938\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 145/1000, validation rmse 1.0148, best validation rmse 0.9224\n",
      "epoch 146/1000, batch 1/8, loss 0.1436\n",
      "epoch 146/1000, training rmse 0.5091\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 146/1000, validation rmse 0.9802, best validation rmse 0.9224\n",
      "epoch 147/1000, batch 1/8, loss 0.1240\n",
      "epoch 147/1000, training rmse 0.5321\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 147/1000, validation rmse 0.9364, best validation rmse 0.9224\n",
      "epoch 148/1000, batch 1/8, loss 0.0914\n",
      "epoch 148/1000, training rmse 0.5384\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 148/1000, validation rmse 0.9581, best validation rmse 0.9224\n",
      "epoch 149/1000, batch 1/8, loss 0.0961\n",
      "epoch 149/1000, training rmse 0.5085\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 149/1000, validation rmse 1.0209, best validation rmse 0.9224\n",
      "epoch 150/1000, batch 1/8, loss 0.1166\n",
      "epoch 150/1000, training rmse 0.5653\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 150/1000, validation rmse 0.9914, best validation rmse 0.9224\n",
      "epoch 151/1000, batch 1/8, loss 0.1040\n",
      "epoch 151/1000, training rmse 0.5607\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 151/1000, validation rmse 1.0275, best validation rmse 0.9224\n",
      "epoch 152/1000, batch 1/8, loss 0.1479\n",
      "epoch 152/1000, training rmse 0.5428\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 152/1000, validation rmse 0.9371, best validation rmse 0.9224\n",
      "epoch 153/1000, batch 1/8, loss 0.1099\n",
      "epoch 153/1000, training rmse 0.6040\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 153/1000, validation rmse 1.0214, best validation rmse 0.9224\n",
      "epoch 154/1000, batch 1/8, loss 0.0998\n",
      "epoch 154/1000, training rmse 0.5214\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 154/1000, validation rmse 0.9505, best validation rmse 0.9224\n",
      "epoch 155/1000, batch 1/8, loss 0.1241\n",
      "epoch 155/1000, training rmse 0.5406\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 155/1000, validation rmse 1.0043, best validation rmse 0.9224\n",
      "epoch 156/1000, batch 1/8, loss 0.1395\n",
      "epoch 156/1000, training rmse 0.5553\n",
      "epoch 156/1000, validation rmse 0.9209, best validation rmse 0.9209\n",
      "epoch 157/1000, batch 1/8, loss 0.1201\n",
      "epoch 157/1000, training rmse 0.5707\n",
      "epoch 157/1000, validation rmse 0.9047, best validation rmse 0.9047\n",
      "epoch 158/1000, batch 1/8, loss 0.1963\n",
      "epoch 158/1000, training rmse 0.5374\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 158/1000, validation rmse 0.9059, best validation rmse 0.9047\n",
      "epoch 159/1000, batch 1/8, loss 0.0715\n",
      "epoch 159/1000, training rmse 0.5055\n",
      "epoch 159/1000, validation rmse 0.8970, best validation rmse 0.8970\n",
      "epoch 160/1000, batch 1/8, loss 0.1072\n",
      "epoch 160/1000, training rmse 0.4958\n",
      "EarlyStopping counter: 1 out of 30\n",
      "epoch 160/1000, validation rmse 0.9496, best validation rmse 0.8970\n",
      "epoch 161/1000, batch 1/8, loss 0.0969\n",
      "epoch 161/1000, training rmse 0.5182\n",
      "EarlyStopping counter: 2 out of 30\n",
      "epoch 161/1000, validation rmse 0.9020, best validation rmse 0.8970\n",
      "epoch 162/1000, batch 1/8, loss 0.1014\n",
      "epoch 162/1000, training rmse 0.5183\n",
      "EarlyStopping counter: 3 out of 30\n",
      "epoch 162/1000, validation rmse 0.9385, best validation rmse 0.8970\n",
      "epoch 163/1000, batch 1/8, loss 0.1866\n",
      "epoch 163/1000, training rmse 0.5168\n",
      "EarlyStopping counter: 4 out of 30\n",
      "epoch 163/1000, validation rmse 0.9192, best validation rmse 0.8970\n",
      "epoch 164/1000, batch 1/8, loss 0.1196\n",
      "epoch 164/1000, training rmse 0.5020\n",
      "EarlyStopping counter: 5 out of 30\n",
      "epoch 164/1000, validation rmse 0.9195, best validation rmse 0.8970\n",
      "epoch 165/1000, batch 1/8, loss 0.1273\n",
      "epoch 165/1000, training rmse 0.5566\n",
      "EarlyStopping counter: 6 out of 30\n",
      "epoch 165/1000, validation rmse 1.0783, best validation rmse 0.8970\n",
      "epoch 166/1000, batch 1/8, loss 0.0893\n",
      "epoch 166/1000, training rmse 0.5734\n",
      "EarlyStopping counter: 7 out of 30\n",
      "epoch 166/1000, validation rmse 0.9501, best validation rmse 0.8970\n",
      "epoch 167/1000, batch 1/8, loss 0.1120\n",
      "epoch 167/1000, training rmse 0.5521\n",
      "EarlyStopping counter: 8 out of 30\n",
      "epoch 167/1000, validation rmse 1.1264, best validation rmse 0.8970\n",
      "epoch 168/1000, batch 1/8, loss 0.1297\n",
      "epoch 168/1000, training rmse 0.5510\n",
      "EarlyStopping counter: 9 out of 30\n",
      "epoch 168/1000, validation rmse 1.0663, best validation rmse 0.8970\n",
      "epoch 169/1000, batch 1/8, loss 0.1011\n",
      "epoch 169/1000, training rmse 0.5303\n",
      "EarlyStopping counter: 10 out of 30\n",
      "epoch 169/1000, validation rmse 1.0074, best validation rmse 0.8970\n",
      "epoch 170/1000, batch 1/8, loss 0.1668\n",
      "epoch 170/1000, training rmse 0.7476\n",
      "EarlyStopping counter: 11 out of 30\n",
      "epoch 170/1000, validation rmse 0.9960, best validation rmse 0.8970\n",
      "epoch 171/1000, batch 1/8, loss 0.1288\n",
      "epoch 171/1000, training rmse 0.5434\n",
      "EarlyStopping counter: 12 out of 30\n",
      "epoch 171/1000, validation rmse 0.9578, best validation rmse 0.8970\n",
      "epoch 172/1000, batch 1/8, loss 0.1176\n",
      "epoch 172/1000, training rmse 0.5232\n",
      "EarlyStopping counter: 13 out of 30\n",
      "epoch 172/1000, validation rmse 1.0051, best validation rmse 0.8970\n",
      "epoch 173/1000, batch 1/8, loss 0.0865\n",
      "epoch 173/1000, training rmse 0.5285\n",
      "EarlyStopping counter: 14 out of 30\n",
      "epoch 173/1000, validation rmse 0.9437, best validation rmse 0.8970\n",
      "epoch 174/1000, batch 1/8, loss 0.1098\n",
      "epoch 174/1000, training rmse 0.6043\n",
      "EarlyStopping counter: 15 out of 30\n",
      "epoch 174/1000, validation rmse 0.9328, best validation rmse 0.8970\n",
      "epoch 175/1000, batch 1/8, loss 0.1258\n",
      "epoch 175/1000, training rmse 0.5708\n",
      "EarlyStopping counter: 16 out of 30\n",
      "epoch 175/1000, validation rmse 0.9666, best validation rmse 0.8970\n",
      "epoch 176/1000, batch 1/8, loss 0.0954\n",
      "epoch 176/1000, training rmse 0.6245\n",
      "EarlyStopping counter: 17 out of 30\n",
      "epoch 176/1000, validation rmse 1.0074, best validation rmse 0.8970\n",
      "epoch 177/1000, batch 1/8, loss 0.1218\n",
      "epoch 177/1000, training rmse 0.5991\n",
      "EarlyStopping counter: 18 out of 30\n",
      "epoch 177/1000, validation rmse 0.9482, best validation rmse 0.8970\n",
      "epoch 178/1000, batch 1/8, loss 0.0861\n",
      "epoch 178/1000, training rmse 0.5223\n",
      "EarlyStopping counter: 19 out of 30\n",
      "epoch 178/1000, validation rmse 0.9374, best validation rmse 0.8970\n",
      "epoch 179/1000, batch 1/8, loss 0.0961\n",
      "epoch 179/1000, training rmse 0.5245\n",
      "EarlyStopping counter: 20 out of 30\n",
      "epoch 179/1000, validation rmse 0.9731, best validation rmse 0.8970\n",
      "epoch 180/1000, batch 1/8, loss 0.1484\n",
      "epoch 180/1000, training rmse 0.5079\n",
      "EarlyStopping counter: 21 out of 30\n",
      "epoch 180/1000, validation rmse 0.9401, best validation rmse 0.8970\n",
      "epoch 181/1000, batch 1/8, loss 0.1034\n",
      "epoch 181/1000, training rmse 0.5408\n",
      "EarlyStopping counter: 22 out of 30\n",
      "epoch 181/1000, validation rmse 1.0432, best validation rmse 0.8970\n",
      "epoch 182/1000, batch 1/8, loss 0.0764\n",
      "epoch 182/1000, training rmse 0.4993\n",
      "EarlyStopping counter: 23 out of 30\n",
      "epoch 182/1000, validation rmse 0.9725, best validation rmse 0.8970\n",
      "epoch 183/1000, batch 1/8, loss 0.0718\n",
      "epoch 183/1000, training rmse 0.5330\n",
      "EarlyStopping counter: 24 out of 30\n",
      "epoch 183/1000, validation rmse 1.1017, best validation rmse 0.8970\n",
      "epoch 184/1000, batch 1/8, loss 0.1116\n",
      "epoch 184/1000, training rmse 0.5515\n",
      "EarlyStopping counter: 25 out of 30\n",
      "epoch 184/1000, validation rmse 0.9079, best validation rmse 0.8970\n",
      "epoch 185/1000, batch 1/8, loss 0.1370\n",
      "epoch 185/1000, training rmse 0.5046\n",
      "EarlyStopping counter: 26 out of 30\n",
      "epoch 185/1000, validation rmse 0.9412, best validation rmse 0.8970\n",
      "epoch 186/1000, batch 1/8, loss 0.0736\n",
      "epoch 186/1000, training rmse 0.4827\n",
      "EarlyStopping counter: 27 out of 30\n",
      "epoch 186/1000, validation rmse 0.8976, best validation rmse 0.8970\n",
      "epoch 187/1000, batch 1/8, loss 0.0942\n",
      "epoch 187/1000, training rmse 0.6319\n",
      "EarlyStopping counter: 28 out of 30\n",
      "epoch 187/1000, validation rmse 0.9851, best validation rmse 0.8970\n",
      "epoch 188/1000, batch 1/8, loss 0.1053\n",
      "epoch 188/1000, training rmse 0.5266\n",
      "EarlyStopping counter: 29 out of 30\n",
      "epoch 188/1000, validation rmse 0.9035, best validation rmse 0.8970\n",
      "epoch 189/1000, batch 1/8, loss 0.1884\n",
      "epoch 189/1000, training rmse 0.5513\n",
      "EarlyStopping counter: 30 out of 30\n",
      "epoch 189/1000, validation rmse 0.9307, best validation rmse 0.8970\n",
      "test rmse 0.8286\n"
     ]
    }
   ],
   "source": [
    "%cd ./csv_data_configuration/\n",
    "!python ./regression_train.py -c ../ESOL/delaney-processed.csv -sc 'smiles' -t 'measured log solubility in mols per litre' -me rmse -nw 0 -p ../regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よりモデル性能を向上させるため、モデルのハイパーパラメータの最適化を行います。\n",
    "`-ne <num_trials>`のオプションを加えることで、`<num_trials>`で指定した回数分ハイパーパラメータの探索(ベイズ最適化)を行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Yusmoris-dgllifesci-handson/dgl-lifesci/examples/property_prediction/csv_data_configuration\n",
      "Using backend: pytorch\n",
      "Directory ../../../../regression_results already exists.\n",
      "Processing dgl graphs from scratch...\n",
      "Processing molecule 1000/1128\n",
      "Start initializing RDKit molecule instances...\n",
      "Creating RDKit molecule instance 1000/1128\n",
      "Start computing Bemis-Murcko scaffolds.\n",
      "Computing Bemis-Murcko for compound 1000/1128\n",
      "Start hyperparameter search with Bayesian optimization for 5 trials\n",
      "Created directory ../../../../regression_results/23                             \n",
      "For metric rmse, the lower the better                                           \n",
      "[2022-12-13 09:08:47.064 pytorch-1-6-cpu-py36--ml-t3-medium-e161cdcbc257f26c3e80f094dd8d:23893 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-12-13 09:08:47.136 pytorch-1-6-cpu-py36--ml-t3-medium-e161cdcbc257f26c3e80f094dd8d:23893 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "epoch 1/1000, batch 1/4, loss 2.6875                                            \n",
      "epoch 1/1000, training rmse 5.6635                                              \n",
      "epoch 1/1000, validation rmse 23.4439, best validation rmse 23.4439             \n",
      "epoch 2/1000, batch 1/4, loss 1.8347                                            \n",
      "epoch 2/1000, training rmse 2.5247                                              \n",
      "epoch 2/1000, validation rmse 13.9001, best validation rmse 13.9001             \n",
      "epoch 3/1000, batch 1/4, loss 1.1842                                            \n",
      "epoch 3/1000, training rmse 1.8279                                              \n",
      "epoch 3/1000, validation rmse 5.3490, best validation rmse 5.3490               \n",
      "epoch 4/1000, batch 1/4, loss 1.0125                                            \n",
      "epoch 4/1000, training rmse 1.5492                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 4/1000, validation rmse 11.8229, best validation rmse 5.3490              \n",
      "epoch 5/1000, batch 1/4, loss 0.8797                                            \n",
      "epoch 5/1000, training rmse 1.4819                                              \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 5/1000, validation rmse 5.5161, best validation rmse 5.3490               \n",
      "epoch 6/1000, batch 1/4, loss 0.7721                                            \n",
      "epoch 6/1000, training rmse 1.3972                                              \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 6/1000, validation rmse 7.8553, best validation rmse 5.3490               \n",
      "epoch 7/1000, batch 1/4, loss 0.6570                                            \n",
      "epoch 7/1000, training rmse 1.3506                                              \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 7/1000, validation rmse 5.9286, best validation rmse 5.3490               \n",
      "epoch 8/1000, batch 1/4, loss 0.6010                                            \n",
      "epoch 8/1000, training rmse 1.2373                                              \n",
      "epoch 8/1000, validation rmse 5.3437, best validation rmse 5.3437               \n",
      "epoch 9/1000, batch 1/4, loss 0.6282                                            \n",
      "epoch 9/1000, training rmse 1.2352                                              \n",
      "epoch 9/1000, validation rmse 4.4176, best validation rmse 4.4176               \n",
      "epoch 10/1000, batch 1/4, loss 0.5394                                           \n",
      "epoch 10/1000, training rmse 1.1819                                             \n",
      "epoch 10/1000, validation rmse 2.9554, best validation rmse 2.9554              \n",
      "epoch 11/1000, batch 1/4, loss 0.4992                                           \n",
      "epoch 11/1000, training rmse 1.1600                                             \n",
      "epoch 11/1000, validation rmse 1.4426, best validation rmse 1.4426              \n",
      "epoch 12/1000, batch 1/4, loss 0.4774                                           \n",
      "epoch 12/1000, training rmse 1.1376                                             \n",
      "epoch 12/1000, validation rmse 1.3294, best validation rmse 1.3294              \n",
      "epoch 13/1000, batch 1/4, loss 0.4635                                           \n",
      "epoch 13/1000, training rmse 0.9701                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 13/1000, validation rmse 1.4412, best validation rmse 1.3294              \n",
      "epoch 14/1000, batch 1/4, loss 0.3279                                           \n",
      "epoch 14/1000, training rmse 0.9697                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 14/1000, validation rmse 1.5100, best validation rmse 1.3294              \n",
      "epoch 15/1000, batch 1/4, loss 0.4549                                           \n",
      "epoch 15/1000, training rmse 1.0170                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 15/1000, validation rmse 1.6781, best validation rmse 1.3294              \n",
      "epoch 16/1000, batch 1/4, loss 0.2948                                           \n",
      "epoch 16/1000, training rmse 0.8842                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 16/1000, validation rmse 1.4489, best validation rmse 1.3294              \n",
      "epoch 17/1000, batch 1/4, loss 0.4746                                           \n",
      "epoch 17/1000, training rmse 1.0119                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 17/1000, validation rmse 1.7605, best validation rmse 1.3294              \n",
      "epoch 18/1000, batch 1/4, loss 0.3152                                           \n",
      "epoch 18/1000, training rmse 0.8587                                             \n",
      "epoch 18/1000, validation rmse 1.2004, best validation rmse 1.2004              \n",
      "epoch 19/1000, batch 1/4, loss 0.3835                                           \n",
      "epoch 19/1000, training rmse 0.9953                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 19/1000, validation rmse 1.6643, best validation rmse 1.2004              \n",
      "epoch 20/1000, batch 1/4, loss 0.3702                                           \n",
      "epoch 20/1000, training rmse 0.9757                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 20/1000, validation rmse 1.9244, best validation rmse 1.2004              \n",
      "epoch 21/1000, batch 1/4, loss 0.2715                                           \n",
      "epoch 21/1000, training rmse 0.9284                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 21/1000, validation rmse 2.5986, best validation rmse 1.2004              \n",
      "epoch 22/1000, batch 1/4, loss 0.3838                                           \n",
      "epoch 22/1000, training rmse 0.9645                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 22/1000, validation rmse 1.9732, best validation rmse 1.2004              \n",
      "epoch 23/1000, batch 1/4, loss 0.2937                                           \n",
      "epoch 23/1000, training rmse 0.9146                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 23/1000, validation rmse 1.5252, best validation rmse 1.2004              \n",
      "epoch 24/1000, batch 1/4, loss 0.3790                                           \n",
      "epoch 24/1000, training rmse 0.9528                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 24/1000, validation rmse 2.1923, best validation rmse 1.2004              \n",
      "epoch 25/1000, batch 1/4, loss 0.4413                                           \n",
      "epoch 25/1000, training rmse 0.9687                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 25/1000, validation rmse 2.1324, best validation rmse 1.2004              \n",
      "epoch 26/1000, batch 1/4, loss 0.3481                                           \n",
      "epoch 26/1000, training rmse 0.8849                                             \n",
      "epoch 26/1000, validation rmse 1.1272, best validation rmse 1.1272              \n",
      "epoch 27/1000, batch 1/4, loss 0.2811                                           \n",
      "epoch 27/1000, training rmse 0.8500                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 27/1000, validation rmse 1.1681, best validation rmse 1.1272              \n",
      "epoch 28/1000, batch 1/4, loss 0.3456                                           \n",
      "epoch 28/1000, training rmse 0.8614                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 28/1000, validation rmse 1.1276, best validation rmse 1.1272              \n",
      "epoch 29/1000, batch 1/4, loss 0.2303                                           \n",
      "epoch 29/1000, training rmse 0.7766                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 29/1000, validation rmse 1.2543, best validation rmse 1.1272              \n",
      "epoch 30/1000, batch 1/4, loss 0.2971                                           \n",
      "epoch 30/1000, training rmse 0.8145                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 30/1000, validation rmse 1.6170, best validation rmse 1.1272              \n",
      "epoch 31/1000, batch 1/4, loss 0.3646                                           \n",
      "epoch 31/1000, training rmse 0.8366                                             \n",
      "epoch 31/1000, validation rmse 1.1090, best validation rmse 1.1090              \n",
      "epoch 32/1000, batch 1/4, loss 0.2860                                           \n",
      "epoch 32/1000, training rmse 0.7927                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 32/1000, validation rmse 1.3538, best validation rmse 1.1090              \n",
      "epoch 33/1000, batch 1/4, loss 0.3028                                           \n",
      "epoch 33/1000, training rmse 0.7479                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 33/1000, validation rmse 1.7271, best validation rmse 1.1090              \n",
      "epoch 34/1000, batch 1/4, loss 0.3466                                           \n",
      "epoch 34/1000, training rmse 0.8118                                             \n",
      "epoch 34/1000, validation rmse 1.1071, best validation rmse 1.1071              \n",
      "epoch 35/1000, batch 1/4, loss 0.2376                                           \n",
      "epoch 35/1000, training rmse 0.7303                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 35/1000, validation rmse 1.6012, best validation rmse 1.1071              \n",
      "epoch 36/1000, batch 1/4, loss 0.2611                                           \n",
      "epoch 36/1000, training rmse 0.7911                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 36/1000, validation rmse 1.5312, best validation rmse 1.1071              \n",
      "epoch 37/1000, batch 1/4, loss 0.3043                                           \n",
      "epoch 37/1000, training rmse 0.8072                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 37/1000, validation rmse 1.3701, best validation rmse 1.1071              \n",
      "epoch 38/1000, batch 1/4, loss 0.3564                                           \n",
      "epoch 38/1000, training rmse 0.8664                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 38/1000, validation rmse 1.1492, best validation rmse 1.1071              \n",
      "epoch 39/1000, batch 1/4, loss 0.2599                                           \n",
      "epoch 39/1000, training rmse 0.7502                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 39/1000, validation rmse 1.2625, best validation rmse 1.1071              \n",
      "epoch 40/1000, batch 1/4, loss 0.2541                                           \n",
      "epoch 40/1000, training rmse 0.7543                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 40/1000, validation rmse 1.1338, best validation rmse 1.1071              \n",
      "epoch 41/1000, batch 1/4, loss 0.2616                                           \n",
      "epoch 41/1000, training rmse 0.8503                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 41/1000, validation rmse 1.8137, best validation rmse 1.1071              \n",
      "epoch 42/1000, batch 1/4, loss 0.3561                                           \n",
      "epoch 42/1000, training rmse 0.9450                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 42/1000, validation rmse 2.1756, best validation rmse 1.1071              \n",
      "epoch 43/1000, batch 1/4, loss 0.3117                                           \n",
      "epoch 43/1000, training rmse 0.8945                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 43/1000, validation rmse 1.4246, best validation rmse 1.1071              \n",
      "epoch 44/1000, batch 1/4, loss 0.3117                                           \n",
      "epoch 44/1000, training rmse 0.8756                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 44/1000, validation rmse 1.4162, best validation rmse 1.1071              \n",
      "epoch 45/1000, batch 1/4, loss 0.3165                                           \n",
      "epoch 45/1000, training rmse 0.7829                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 45/1000, validation rmse 1.2719, best validation rmse 1.1071              \n",
      "epoch 46/1000, batch 1/4, loss 0.2024                                           \n",
      "epoch 46/1000, training rmse 0.7541                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 46/1000, validation rmse 1.1725, best validation rmse 1.1071              \n",
      "epoch 47/1000, batch 1/4, loss 0.2565                                           \n",
      "epoch 47/1000, training rmse 0.7759                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 47/1000, validation rmse 1.1385, best validation rmse 1.1071              \n",
      "epoch 48/1000, batch 1/4, loss 0.2523                                           \n",
      "epoch 48/1000, training rmse 0.7531                                             \n",
      "epoch 48/1000, validation rmse 1.0886, best validation rmse 1.0886              \n",
      "epoch 49/1000, batch 1/4, loss 0.2445                                           \n",
      "epoch 49/1000, training rmse 0.7677                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 49/1000, validation rmse 1.1594, best validation rmse 1.0886              \n",
      "epoch 50/1000, batch 1/4, loss 0.2389                                           \n",
      "epoch 50/1000, training rmse 0.7663                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 50/1000, validation rmse 1.1341, best validation rmse 1.0886              \n",
      "epoch 51/1000, batch 1/4, loss 0.2188                                           \n",
      "epoch 51/1000, training rmse 0.7657                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 51/1000, validation rmse 1.1892, best validation rmse 1.0886              \n",
      "epoch 52/1000, batch 1/4, loss 0.2157                                           \n",
      "epoch 52/1000, training rmse 0.7555                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 52/1000, validation rmse 1.1225, best validation rmse 1.0886              \n",
      "epoch 53/1000, batch 1/4, loss 0.2369                                           \n",
      "epoch 53/1000, training rmse 0.7649                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 53/1000, validation rmse 1.1177, best validation rmse 1.0886              \n",
      "epoch 54/1000, batch 1/4, loss 0.2273                                           \n",
      "epoch 54/1000, training rmse 0.7016                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 54/1000, validation rmse 1.1595, best validation rmse 1.0886              \n",
      "epoch 55/1000, batch 1/4, loss 0.2073                                           \n",
      "epoch 55/1000, training rmse 0.7288                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 55/1000, validation rmse 1.9892, best validation rmse 1.0886              \n",
      "epoch 56/1000, batch 1/4, loss 0.2432                                           \n",
      "epoch 56/1000, training rmse 0.7609                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 56/1000, validation rmse 1.1734, best validation rmse 1.0886              \n",
      "epoch 57/1000, batch 1/4, loss 0.2237                                           \n",
      "epoch 57/1000, training rmse 0.7759                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 57/1000, validation rmse 1.2591, best validation rmse 1.0886              \n",
      "epoch 58/1000, batch 1/4, loss 0.2366                                           \n",
      "epoch 58/1000, training rmse 0.7149                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 58/1000, validation rmse 1.3623, best validation rmse 1.0886              \n",
      "epoch 59/1000, batch 1/4, loss 0.2422                                           \n",
      "epoch 59/1000, training rmse 0.7109                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 59/1000, validation rmse 1.2945, best validation rmse 1.0886              \n",
      "epoch 60/1000, batch 1/4, loss 0.1815                                           \n",
      "epoch 60/1000, training rmse 0.7184                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 60/1000, validation rmse 1.1804, best validation rmse 1.0886              \n",
      "epoch 61/1000, batch 1/4, loss 0.2724                                           \n",
      "epoch 61/1000, training rmse 0.7834                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 61/1000, validation rmse 1.3106, best validation rmse 1.0886              \n",
      "epoch 62/1000, batch 1/4, loss 0.2749                                           \n",
      "epoch 62/1000, training rmse 0.8135                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 62/1000, validation rmse 1.3498, best validation rmse 1.0886              \n",
      "epoch 63/1000, batch 1/4, loss 0.2376                                           \n",
      "epoch 63/1000, training rmse 0.8791                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 63/1000, validation rmse 1.4855, best validation rmse 1.0886              \n",
      "epoch 64/1000, batch 1/4, loss 0.2925                                           \n",
      "epoch 64/1000, training rmse 0.8847                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 64/1000, validation rmse 1.3592, best validation rmse 1.0886              \n",
      "epoch 65/1000, batch 1/4, loss 0.2234                                           \n",
      "epoch 65/1000, training rmse 0.7160                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 65/1000, validation rmse 1.3526, best validation rmse 1.0886              \n",
      "epoch 66/1000, batch 1/4, loss 0.2061                                           \n",
      "epoch 66/1000, training rmse 0.7346                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 66/1000, validation rmse 1.3667, best validation rmse 1.0886              \n",
      "epoch 67/1000, batch 1/4, loss 0.2626                                           \n",
      "epoch 67/1000, training rmse 0.7813                                             \n",
      "epoch 67/1000, validation rmse 1.0760, best validation rmse 1.0760              \n",
      "epoch 68/1000, batch 1/4, loss 0.2018                                           \n",
      "epoch 68/1000, training rmse 0.7389                                             \n",
      "epoch 68/1000, validation rmse 1.0596, best validation rmse 1.0596              \n",
      "epoch 69/1000, batch 1/4, loss 0.2287                                           \n",
      "epoch 69/1000, training rmse 0.7272                                             \n",
      "epoch 69/1000, validation rmse 1.0278, best validation rmse 1.0278              \n",
      "epoch 70/1000, batch 1/4, loss 0.1956                                           \n",
      "epoch 70/1000, training rmse 0.7195                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 70/1000, validation rmse 1.4496, best validation rmse 1.0278              \n",
      "epoch 71/1000, batch 1/4, loss 0.2196                                           \n",
      "epoch 71/1000, training rmse 0.7585                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 71/1000, validation rmse 1.2409, best validation rmse 1.0278              \n",
      "epoch 72/1000, batch 1/4, loss 0.2953                                           \n",
      "epoch 72/1000, training rmse 0.7964                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 72/1000, validation rmse 1.3174, best validation rmse 1.0278              \n",
      "epoch 73/1000, batch 1/4, loss 0.2453                                           \n",
      "epoch 73/1000, training rmse 0.7612                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 73/1000, validation rmse 1.1287, best validation rmse 1.0278              \n",
      "epoch 74/1000, batch 1/4, loss 0.2169                                           \n",
      "epoch 74/1000, training rmse 0.7575                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 74/1000, validation rmse 1.1269, best validation rmse 1.0278              \n",
      "epoch 75/1000, batch 1/4, loss 0.2283                                           \n",
      "epoch 75/1000, training rmse 0.7465                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 75/1000, validation rmse 1.2042, best validation rmse 1.0278              \n",
      "epoch 76/1000, batch 1/4, loss 0.2611                                           \n",
      "epoch 76/1000, training rmse 0.7471                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 76/1000, validation rmse 1.1696, best validation rmse 1.0278              \n",
      "epoch 77/1000, batch 1/4, loss 0.1955                                           \n",
      "epoch 77/1000, training rmse 0.6954                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 77/1000, validation rmse 1.1639, best validation rmse 1.0278              \n",
      "epoch 78/1000, batch 1/4, loss 0.2399                                           \n",
      "epoch 78/1000, training rmse 0.6748                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 78/1000, validation rmse 1.3534, best validation rmse 1.0278              \n",
      "epoch 79/1000, batch 1/4, loss 0.1993                                           \n",
      "epoch 79/1000, training rmse 0.7495                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 79/1000, validation rmse 1.0695, best validation rmse 1.0278              \n",
      "epoch 80/1000, batch 1/4, loss 0.2402                                           \n",
      "epoch 80/1000, training rmse 0.7325                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 80/1000, validation rmse 1.1441, best validation rmse 1.0278              \n",
      "epoch 81/1000, batch 1/4, loss 0.2580                                           \n",
      "epoch 81/1000, training rmse 0.7623                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 81/1000, validation rmse 1.2130, best validation rmse 1.0278              \n",
      "epoch 82/1000, batch 1/4, loss 0.2288                                           \n",
      "epoch 82/1000, training rmse 0.7699                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 82/1000, validation rmse 1.9031, best validation rmse 1.0278              \n",
      "epoch 83/1000, batch 1/4, loss 0.2248                                           \n",
      "epoch 83/1000, training rmse 0.7299                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 83/1000, validation rmse 1.1125, best validation rmse 1.0278              \n",
      "epoch 84/1000, batch 1/4, loss 0.2203                                           \n",
      "epoch 84/1000, training rmse 0.6764                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 84/1000, validation rmse 1.5513, best validation rmse 1.0278              \n",
      "epoch 85/1000, batch 1/4, loss 0.2116                                           \n",
      "epoch 85/1000, training rmse 0.7406                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 85/1000, validation rmse 1.2041, best validation rmse 1.0278              \n",
      "epoch 86/1000, batch 1/4, loss 0.2163                                           \n",
      "epoch 86/1000, training rmse 0.7109                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 86/1000, validation rmse 1.1035, best validation rmse 1.0278              \n",
      "epoch 87/1000, batch 1/4, loss 0.1745                                           \n",
      "epoch 87/1000, training rmse 0.7379                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 87/1000, validation rmse 1.1407, best validation rmse 1.0278              \n",
      "epoch 88/1000, batch 1/4, loss 0.2701                                           \n",
      "epoch 88/1000, training rmse 0.7107                                             \n",
      "EarlyStopping counter: 19 out of 30                                             \n",
      "epoch 88/1000, validation rmse 1.0666, best validation rmse 1.0278              \n",
      "epoch 89/1000, batch 1/4, loss 0.1867                                           \n",
      "epoch 89/1000, training rmse 0.6717                                             \n",
      "EarlyStopping counter: 20 out of 30                                             \n",
      "epoch 89/1000, validation rmse 1.1620, best validation rmse 1.0278              \n",
      "epoch 90/1000, batch 1/4, loss 0.1913                                           \n",
      "epoch 90/1000, training rmse 0.6730                                             \n",
      "EarlyStopping counter: 21 out of 30                                             \n",
      "epoch 90/1000, validation rmse 1.2895, best validation rmse 1.0278              \n",
      "epoch 91/1000, batch 1/4, loss 0.2154                                           \n",
      "epoch 91/1000, training rmse 0.7068                                             \n",
      "EarlyStopping counter: 22 out of 30                                             \n",
      "epoch 91/1000, validation rmse 1.1126, best validation rmse 1.0278              \n",
      "epoch 92/1000, batch 1/4, loss 0.2186                                           \n",
      "epoch 92/1000, training rmse 0.7395                                             \n",
      "EarlyStopping counter: 23 out of 30                                             \n",
      "epoch 92/1000, validation rmse 1.6511, best validation rmse 1.0278              \n",
      "epoch 93/1000, batch 1/4, loss 0.1900                                           \n",
      "epoch 93/1000, training rmse 0.6800                                             \n",
      "EarlyStopping counter: 24 out of 30                                             \n",
      "epoch 93/1000, validation rmse 1.0860, best validation rmse 1.0278              \n",
      "epoch 94/1000, batch 1/4, loss 0.1893                                           \n",
      "epoch 94/1000, training rmse 0.7704                                             \n",
      "EarlyStopping counter: 25 out of 30                                             \n",
      "epoch 94/1000, validation rmse 1.4191, best validation rmse 1.0278              \n",
      "epoch 95/1000, batch 1/4, loss 0.2650                                           \n",
      "epoch 95/1000, training rmse 0.7805                                             \n",
      "EarlyStopping counter: 26 out of 30                                             \n",
      "epoch 95/1000, validation rmse 1.9437, best validation rmse 1.0278              \n",
      "epoch 96/1000, batch 1/4, loss 0.2986                                           \n",
      "epoch 96/1000, training rmse 0.7802                                             \n",
      "EarlyStopping counter: 27 out of 30                                             \n",
      "epoch 96/1000, validation rmse 1.5091, best validation rmse 1.0278              \n",
      "epoch 97/1000, batch 1/4, loss 0.1981                                           \n",
      "epoch 97/1000, training rmse 0.7125                                             \n",
      "EarlyStopping counter: 28 out of 30                                             \n",
      "epoch 97/1000, validation rmse 1.3219, best validation rmse 1.0278              \n",
      "epoch 98/1000, batch 1/4, loss 0.1854                                           \n",
      "epoch 98/1000, training rmse 0.7059                                             \n",
      "EarlyStopping counter: 29 out of 30                                             \n",
      "epoch 98/1000, validation rmse 1.8347, best validation rmse 1.0278              \n",
      "epoch 99/1000, batch 1/4, loss 0.2102                                           \n",
      "epoch 99/1000, training rmse 0.6909                                             \n",
      "EarlyStopping counter: 30 out of 30                                             \n",
      "epoch 99/1000, validation rmse 1.0516, best validation rmse 1.0278              \n",
      "test rmse 0.9280                                                                \n",
      " 20%|██▏        | 1/5 [00:12<00:51, 12.88s/trial, best loss: 1.0277615785598755]INFO:hyperopt.tpe:build_posterior_wrapper took 0.003968 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 1.027762\n",
      "Created directory ../../../../regression_results/24                             \n",
      "For metric rmse, the lower the better                                           \n",
      "epoch 1/1000, batch 1/8, loss 2.5027                                            \n",
      "epoch 1/1000, training rmse 3.4181                                              \n",
      "epoch 1/1000, validation rmse 49.7658, best validation rmse 49.7658             \n",
      "epoch 2/1000, batch 1/8, loss 2.1188                                            \n",
      "epoch 2/1000, training rmse 2.2591                                              \n",
      "epoch 2/1000, validation rmse 22.6939, best validation rmse 22.6939             \n",
      "epoch 3/1000, batch 1/8, loss 1.2239                                            \n",
      "epoch 3/1000, training rmse 1.7663                                              \n",
      "epoch 3/1000, validation rmse 2.1954, best validation rmse 2.1954               \n",
      "epoch 4/1000, batch 1/8, loss 1.3061                                            \n",
      "epoch 4/1000, training rmse 1.8697                                              \n",
      "epoch 4/1000, validation rmse 1.8234, best validation rmse 1.8234               \n",
      "epoch 5/1000, batch 1/8, loss 0.7538                                            \n",
      "epoch 5/1000, training rmse 1.8103                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 5/1000, validation rmse 2.0699, best validation rmse 1.8234               \n",
      "epoch 6/1000, batch 1/8, loss 1.0851                                            \n",
      "epoch 6/1000, training rmse 1.6505                                              \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 6/1000, validation rmse 1.8558, best validation rmse 1.8234               \n",
      "epoch 7/1000, batch 1/8, loss 0.8826                                            \n",
      "epoch 7/1000, training rmse 1.5313                                              \n",
      "epoch 7/1000, validation rmse 1.7052, best validation rmse 1.7052               \n",
      "epoch 8/1000, batch 1/8, loss 0.7240                                            \n",
      "epoch 8/1000, training rmse 1.4320                                              \n",
      "epoch 8/1000, validation rmse 1.4984, best validation rmse 1.4984               \n",
      "epoch 9/1000, batch 1/8, loss 0.7659                                            \n",
      "epoch 9/1000, training rmse 1.4770                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 9/1000, validation rmse 1.6240, best validation rmse 1.4984               \n",
      "epoch 10/1000, batch 1/8, loss 0.6592                                           \n",
      "epoch 10/1000, training rmse 1.5247                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 10/1000, validation rmse 1.6905, best validation rmse 1.4984              \n",
      "epoch 11/1000, batch 1/8, loss 0.5644                                           \n",
      "epoch 11/1000, training rmse 1.4998                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 11/1000, validation rmse 3.8544, best validation rmse 1.4984              \n",
      "epoch 12/1000, batch 1/8, loss 0.9222                                           \n",
      "epoch 12/1000, training rmse 1.4779                                             \n",
      "epoch 12/1000, validation rmse 1.4216, best validation rmse 1.4216              \n",
      "epoch 13/1000, batch 1/8, loss 0.5595                                           \n",
      "epoch 13/1000, training rmse 1.4163                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 13/1000, validation rmse 3.6703, best validation rmse 1.4216              \n",
      "epoch 14/1000, batch 1/8, loss 0.8055                                           \n",
      "epoch 14/1000, training rmse 1.4461                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 14/1000, validation rmse 1.9033, best validation rmse 1.4216              \n",
      "epoch 15/1000, batch 1/8, loss 0.6312                                           \n",
      "epoch 15/1000, training rmse 1.3815                                             \n",
      "epoch 15/1000, validation rmse 1.3113, best validation rmse 1.3113              \n",
      "epoch 16/1000, batch 1/8, loss 0.6693                                           \n",
      "epoch 16/1000, training rmse 1.3259                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 16/1000, validation rmse 2.2812, best validation rmse 1.3113              \n",
      "epoch 17/1000, batch 1/8, loss 0.5051                                           \n",
      "epoch 17/1000, training rmse 1.3073                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 17/1000, validation rmse 3.1097, best validation rmse 1.3113              \n",
      "epoch 18/1000, batch 1/8, loss 0.7212                                           \n",
      "epoch 18/1000, training rmse 1.4286                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 18/1000, validation rmse 1.4025, best validation rmse 1.3113              \n",
      "epoch 19/1000, batch 1/8, loss 0.6250                                           \n",
      "epoch 19/1000, training rmse 1.2734                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 19/1000, validation rmse 4.8418, best validation rmse 1.3113              \n",
      "epoch 20/1000, batch 1/8, loss 0.5356                                           \n",
      "epoch 20/1000, training rmse 1.2776                                             \n",
      "epoch 20/1000, validation rmse 1.2728, best validation rmse 1.2728              \n",
      "epoch 21/1000, batch 1/8, loss 0.5075                                           \n",
      "epoch 21/1000, training rmse 1.2553                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 21/1000, validation rmse 1.3500, best validation rmse 1.2728              \n",
      "epoch 22/1000, batch 1/8, loss 0.5253                                           \n",
      "epoch 22/1000, training rmse 1.2387                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 22/1000, validation rmse 1.3919, best validation rmse 1.2728              \n",
      "epoch 23/1000, batch 1/8, loss 0.4745                                           \n",
      "epoch 23/1000, training rmse 1.2246                                             \n",
      "epoch 23/1000, validation rmse 1.2337, best validation rmse 1.2337              \n",
      "epoch 24/1000, batch 1/8, loss 0.6292                                           \n",
      "epoch 24/1000, training rmse 1.2303                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 24/1000, validation rmse 1.4305, best validation rmse 1.2337              \n",
      "epoch 25/1000, batch 1/8, loss 0.7765                                           \n",
      "epoch 25/1000, training rmse 1.3136                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 25/1000, validation rmse 1.5762, best validation rmse 1.2337              \n",
      "epoch 26/1000, batch 1/8, loss 0.6605                                           \n",
      "epoch 26/1000, training rmse 1.2213                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 26/1000, validation rmse 2.0946, best validation rmse 1.2337              \n",
      "epoch 27/1000, batch 1/8, loss 0.6505                                           \n",
      "epoch 27/1000, training rmse 1.2188                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 27/1000, validation rmse 1.3461, best validation rmse 1.2337              \n",
      "epoch 28/1000, batch 1/8, loss 0.3943                                           \n",
      "epoch 28/1000, training rmse 1.2365                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 28/1000, validation rmse 1.4094, best validation rmse 1.2337              \n",
      "epoch 29/1000, batch 1/8, loss 0.5792                                           \n",
      "epoch 29/1000, training rmse 1.1758                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 29/1000, validation rmse 1.4353, best validation rmse 1.2337              \n",
      "epoch 30/1000, batch 1/8, loss 0.4946                                           \n",
      "epoch 30/1000, training rmse 1.1320                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 30/1000, validation rmse 2.0253, best validation rmse 1.2337              \n",
      "epoch 31/1000, batch 1/8, loss 0.6300                                           \n",
      "epoch 31/1000, training rmse 1.1807                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 31/1000, validation rmse 1.9163, best validation rmse 1.2337              \n",
      "epoch 32/1000, batch 1/8, loss 0.5953                                           \n",
      "epoch 32/1000, training rmse 1.1556                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 32/1000, validation rmse 1.4437, best validation rmse 1.2337              \n",
      "epoch 33/1000, batch 1/8, loss 0.4115                                           \n",
      "epoch 33/1000, training rmse 1.1304                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 33/1000, validation rmse 2.0986, best validation rmse 1.2337              \n",
      "epoch 34/1000, batch 1/8, loss 0.5734                                           \n",
      "epoch 34/1000, training rmse 1.1566                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 34/1000, validation rmse 1.2941, best validation rmse 1.2337              \n",
      "epoch 35/1000, batch 1/8, loss 0.5065                                           \n",
      "epoch 35/1000, training rmse 1.0812                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 35/1000, validation rmse 1.7139, best validation rmse 1.2337              \n",
      "epoch 36/1000, batch 1/8, loss 0.4582                                           \n",
      "epoch 36/1000, training rmse 1.1391                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 36/1000, validation rmse 1.3756, best validation rmse 1.2337              \n",
      "epoch 37/1000, batch 1/8, loss 0.4862                                           \n",
      "epoch 37/1000, training rmse 1.0286                                             \n",
      "epoch 37/1000, validation rmse 1.1628, best validation rmse 1.1628              \n",
      "epoch 38/1000, batch 1/8, loss 0.4294                                           \n",
      "epoch 38/1000, training rmse 1.0704                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 38/1000, validation rmse 2.6337, best validation rmse 1.1628              \n",
      "epoch 39/1000, batch 1/8, loss 0.6248                                           \n",
      "epoch 39/1000, training rmse 1.3548                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 39/1000, validation rmse 2.8342, best validation rmse 1.1628              \n",
      "epoch 40/1000, batch 1/8, loss 0.8686                                           \n",
      "epoch 40/1000, training rmse 1.3160                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 40/1000, validation rmse 1.1905, best validation rmse 1.1628              \n",
      "epoch 41/1000, batch 1/8, loss 0.7168                                           \n",
      "epoch 41/1000, training rmse 1.3698                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 41/1000, validation rmse 1.1830, best validation rmse 1.1628              \n",
      "epoch 42/1000, batch 1/8, loss 0.6382                                           \n",
      "epoch 42/1000, training rmse 1.2058                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 42/1000, validation rmse 1.5703, best validation rmse 1.1628              \n",
      "epoch 43/1000, batch 1/8, loss 0.7731                                           \n",
      "epoch 43/1000, training rmse 1.3342                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 43/1000, validation rmse 1.6971, best validation rmse 1.1628              \n",
      "epoch 44/1000, batch 1/8, loss 0.9564                                           \n",
      "epoch 44/1000, training rmse 1.2852                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 44/1000, validation rmse 1.9060, best validation rmse 1.1628              \n",
      "epoch 45/1000, batch 1/8, loss 0.7494                                           \n",
      "epoch 45/1000, training rmse 1.3073                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 45/1000, validation rmse 1.3430, best validation rmse 1.1628              \n",
      "epoch 46/1000, batch 1/8, loss 0.5033                                           \n",
      "epoch 46/1000, training rmse 1.1787                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 46/1000, validation rmse 1.2015, best validation rmse 1.1628              \n",
      "epoch 47/1000, batch 1/8, loss 0.4230                                           \n",
      "epoch 47/1000, training rmse 1.1319                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 47/1000, validation rmse 1.2822, best validation rmse 1.1628              \n",
      "epoch 48/1000, batch 1/8, loss 0.4972                                           \n",
      "epoch 48/1000, training rmse 1.1850                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 48/1000, validation rmse 1.7656, best validation rmse 1.1628              \n",
      "epoch 49/1000, batch 1/8, loss 0.6702                                           \n",
      "epoch 49/1000, training rmse 1.2406                                             \n",
      "epoch 49/1000, validation rmse 1.0110, best validation rmse 1.0110              \n",
      "epoch 50/1000, batch 1/8, loss 0.4712                                           \n",
      "epoch 50/1000, training rmse 1.1209                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 50/1000, validation rmse 1.3798, best validation rmse 1.0110              \n",
      "epoch 51/1000, batch 1/8, loss 0.4080                                           \n",
      "epoch 51/1000, training rmse 1.2272                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 51/1000, validation rmse 2.0863, best validation rmse 1.0110              \n",
      "epoch 52/1000, batch 1/8, loss 0.5096                                           \n",
      "epoch 52/1000, training rmse 1.1995                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 52/1000, validation rmse 1.7909, best validation rmse 1.0110              \n",
      "epoch 53/1000, batch 1/8, loss 0.7377                                           \n",
      "epoch 53/1000, training rmse 1.3002                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 53/1000, validation rmse 1.2042, best validation rmse 1.0110              \n",
      "epoch 54/1000, batch 1/8, loss 0.7931                                           \n",
      "epoch 54/1000, training rmse 1.2204                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 54/1000, validation rmse 1.5613, best validation rmse 1.0110              \n",
      "epoch 55/1000, batch 1/8, loss 0.9707                                           \n",
      "epoch 55/1000, training rmse 1.3367                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 55/1000, validation rmse 1.4746, best validation rmse 1.0110              \n",
      "epoch 56/1000, batch 1/8, loss 0.5652                                           \n",
      "epoch 56/1000, training rmse 1.3175                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 56/1000, validation rmse 1.4986, best validation rmse 1.0110              \n",
      "epoch 57/1000, batch 1/8, loss 0.9007                                           \n",
      "epoch 57/1000, training rmse 1.3582                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 57/1000, validation rmse 1.1508, best validation rmse 1.0110              \n",
      "epoch 58/1000, batch 1/8, loss 1.0044                                           \n",
      "epoch 58/1000, training rmse 1.3582                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 58/1000, validation rmse 1.4338, best validation rmse 1.0110              \n",
      "epoch 59/1000, batch 1/8, loss 1.0435                                           \n",
      "epoch 59/1000, training rmse 1.3755                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 59/1000, validation rmse 1.5346, best validation rmse 1.0110              \n",
      "epoch 60/1000, batch 1/8, loss 0.8100                                           \n",
      "epoch 60/1000, training rmse 1.2366                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 60/1000, validation rmse 1.2871, best validation rmse 1.0110              \n",
      "epoch 61/1000, batch 1/8, loss 0.5038                                           \n",
      "epoch 61/1000, training rmse 1.1050                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 61/1000, validation rmse 1.3894, best validation rmse 1.0110              \n",
      "epoch 62/1000, batch 1/8, loss 0.4986                                           \n",
      "epoch 62/1000, training rmse 1.1571                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 62/1000, validation rmse 1.8193, best validation rmse 1.0110              \n",
      "epoch 63/1000, batch 1/8, loss 0.4229                                           \n",
      "epoch 63/1000, training rmse 1.1122                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 63/1000, validation rmse 2.3171, best validation rmse 1.0110              \n",
      "epoch 64/1000, batch 1/8, loss 0.4948                                           \n",
      "epoch 64/1000, training rmse 1.0449                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 64/1000, validation rmse 1.4988, best validation rmse 1.0110              \n",
      "epoch 65/1000, batch 1/8, loss 0.4228                                           \n",
      "epoch 65/1000, training rmse 1.1025                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 65/1000, validation rmse 2.6307, best validation rmse 1.0110              \n",
      "epoch 66/1000, batch 1/8, loss 0.5614                                           \n",
      "epoch 66/1000, training rmse 1.2553                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 66/1000, validation rmse 1.4088, best validation rmse 1.0110              \n",
      "epoch 67/1000, batch 1/8, loss 0.4441                                           \n",
      "epoch 67/1000, training rmse 1.1628                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 67/1000, validation rmse 1.1570, best validation rmse 1.0110              \n",
      "epoch 68/1000, batch 1/8, loss 0.7054                                           \n",
      "epoch 68/1000, training rmse 1.1752                                             \n",
      "EarlyStopping counter: 19 out of 30                                             \n",
      "epoch 68/1000, validation rmse 1.0628, best validation rmse 1.0110              \n",
      "epoch 69/1000, batch 1/8, loss 0.5874                                           \n",
      "epoch 69/1000, training rmse 1.1815                                             \n",
      "EarlyStopping counter: 20 out of 30                                             \n",
      "epoch 69/1000, validation rmse 1.3200, best validation rmse 1.0110              \n",
      "epoch 70/1000, batch 1/8, loss 0.4727                                           \n",
      "epoch 70/1000, training rmse 1.2351                                             \n",
      "EarlyStopping counter: 21 out of 30                                             \n",
      "epoch 70/1000, validation rmse 1.2189, best validation rmse 1.0110              \n",
      "epoch 71/1000, batch 1/8, loss 0.4332                                           \n",
      "epoch 71/1000, training rmse 1.1525                                             \n",
      "EarlyStopping counter: 22 out of 30                                             \n",
      "epoch 71/1000, validation rmse 1.5145, best validation rmse 1.0110              \n",
      "epoch 72/1000, batch 1/8, loss 0.4845                                           \n",
      "epoch 72/1000, training rmse 1.1092                                             \n",
      "EarlyStopping counter: 23 out of 30                                             \n",
      "epoch 72/1000, validation rmse 2.5661, best validation rmse 1.0110              \n",
      "epoch 73/1000, batch 1/8, loss 0.4060                                           \n",
      "epoch 73/1000, training rmse 1.1319                                             \n",
      "EarlyStopping counter: 24 out of 30                                             \n",
      "epoch 73/1000, validation rmse 1.6131, best validation rmse 1.0110              \n",
      "epoch 74/1000, batch 1/8, loss 0.4671                                           \n",
      "epoch 74/1000, training rmse 1.1000                                             \n",
      "EarlyStopping counter: 25 out of 30                                             \n",
      "epoch 74/1000, validation rmse 1.7318, best validation rmse 1.0110              \n",
      "epoch 75/1000, batch 1/8, loss 0.4484                                           \n",
      "epoch 75/1000, training rmse 1.0819                                             \n",
      "EarlyStopping counter: 26 out of 30                                             \n",
      "epoch 75/1000, validation rmse 1.2579, best validation rmse 1.0110              \n",
      "epoch 76/1000, batch 1/8, loss 0.5948                                           \n",
      "epoch 76/1000, training rmse 1.1990                                             \n",
      "EarlyStopping counter: 27 out of 30                                             \n",
      "epoch 76/1000, validation rmse 2.4946, best validation rmse 1.0110              \n",
      "epoch 77/1000, batch 1/8, loss 0.5744                                           \n",
      "epoch 77/1000, training rmse 1.1289                                             \n",
      "EarlyStopping counter: 28 out of 30                                             \n",
      "epoch 77/1000, validation rmse 1.4332, best validation rmse 1.0110              \n",
      "epoch 78/1000, batch 1/8, loss 0.5340                                           \n",
      "epoch 78/1000, training rmse 1.1481                                             \n",
      "EarlyStopping counter: 29 out of 30                                             \n",
      "epoch 78/1000, validation rmse 1.1815, best validation rmse 1.0110              \n",
      "epoch 79/1000, batch 1/8, loss 0.4884                                           \n",
      "epoch 79/1000, training rmse 1.1304                                             \n",
      "EarlyStopping counter: 30 out of 30                                             \n",
      "epoch 79/1000, validation rmse 2.1882, best validation rmse 1.0110              \n",
      "test rmse 0.9410                                                                \n",
      " 40%|████▍      | 2/5 [00:37<00:48, 16.28s/trial, best loss: 1.0110034942626953]INFO:hyperopt.tpe:build_posterior_wrapper took 0.004028 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 1.011003\n",
      "Created directory ../../../../regression_results/25                             \n",
      "For metric rmse, the lower the better                                           \n",
      "epoch 1/1000, batch 1/2, loss 2.6517                                            \n",
      "epoch 1/1000, training rmse 3.5700                                              \n",
      "epoch 1/1000, validation rmse 8.5558, best validation rmse 8.5558               \n",
      "epoch 2/1000, batch 1/2, loss 2.3339                                            \n",
      "epoch 2/1000, training rmse 3.3110                                              \n",
      "epoch 2/1000, validation rmse 2.7268, best validation rmse 2.7268               \n",
      "epoch 3/1000, batch 1/2, loss 2.3545                                            \n",
      "epoch 3/1000, training rmse 3.1998                                              \n",
      "epoch 3/1000, validation rmse 1.6721, best validation rmse 1.6721               \n",
      "epoch 4/1000, batch 1/2, loss 2.0997                                            \n",
      "epoch 4/1000, training rmse 3.0251                                              \n",
      "epoch 4/1000, validation rmse 1.5652, best validation rmse 1.5652               \n",
      "epoch 5/1000, batch 1/2, loss 1.9647                                            \n",
      "epoch 5/1000, training rmse 2.8260                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 5/1000, validation rmse 1.9403, best validation rmse 1.5652               \n",
      "epoch 6/1000, batch 1/2, loss 1.7115                                            \n",
      "epoch 6/1000, training rmse 2.5865                                              \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 6/1000, validation rmse 2.5732, best validation rmse 1.5652               \n",
      "epoch 7/1000, batch 1/2, loss 1.4134                                            \n",
      "epoch 7/1000, training rmse 2.2923                                              \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 7/1000, validation rmse 3.1310, best validation rmse 1.5652               \n",
      "epoch 8/1000, batch 1/2, loss 1.2029                                            \n",
      "epoch 8/1000, training rmse 1.9297                                              \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 8/1000, validation rmse 1.9118, best validation rmse 1.5652               \n",
      "epoch 9/1000, batch 1/2, loss 0.9269                                            \n",
      "epoch 9/1000, training rmse 1.6011                                              \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 9/1000, validation rmse 1.6330, best validation rmse 1.5652               \n",
      "epoch 10/1000, batch 1/2, loss 0.6832                                           \n",
      "epoch 10/1000, training rmse 1.3842                                             \n",
      "epoch 10/1000, validation rmse 1.4087, best validation rmse 1.4087              \n",
      "epoch 11/1000, batch 1/2, loss 0.7017                                           \n",
      "epoch 11/1000, training rmse 1.4067                                             \n",
      "epoch 11/1000, validation rmse 1.2330, best validation rmse 1.2330              \n",
      "epoch 12/1000, batch 1/2, loss 0.7548                                           \n",
      "epoch 12/1000, training rmse 1.4464                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 12/1000, validation rmse 1.2871, best validation rmse 1.2330              \n",
      "epoch 13/1000, batch 1/2, loss 0.7237                                           \n",
      "epoch 13/1000, training rmse 1.5217                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 13/1000, validation rmse 1.5762, best validation rmse 1.2330              \n",
      "epoch 14/1000, batch 1/2, loss 0.7846                                           \n",
      "epoch 14/1000, training rmse 1.3921                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 14/1000, validation rmse 1.9538, best validation rmse 1.2330              \n",
      "epoch 15/1000, batch 1/2, loss 0.6903                                           \n",
      "epoch 15/1000, training rmse 1.2927                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 15/1000, validation rmse 1.5025, best validation rmse 1.2330              \n",
      "epoch 16/1000, batch 1/2, loss 0.5698                                           \n",
      "epoch 16/1000, training rmse 1.2014                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 16/1000, validation rmse 1.6201, best validation rmse 1.2330              \n",
      "epoch 17/1000, batch 1/2, loss 0.5948                                           \n",
      "epoch 17/1000, training rmse 1.2386                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 17/1000, validation rmse 2.1870, best validation rmse 1.2330              \n",
      "epoch 18/1000, batch 1/2, loss 0.6161                                           \n",
      "epoch 18/1000, training rmse 1.2840                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 18/1000, validation rmse 1.2735, best validation rmse 1.2330              \n",
      "epoch 19/1000, batch 1/2, loss 0.6314                                           \n",
      "epoch 19/1000, training rmse 1.2761                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 19/1000, validation rmse 1.2527, best validation rmse 1.2330              \n",
      "epoch 20/1000, batch 1/2, loss 0.5439                                           \n",
      "epoch 20/1000, training rmse 1.2073                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 20/1000, validation rmse 1.3001, best validation rmse 1.2330              \n",
      "epoch 21/1000, batch 1/2, loss 0.6565                                           \n",
      "epoch 21/1000, training rmse 1.3000                                             \n",
      "epoch 21/1000, validation rmse 1.1936, best validation rmse 1.1936              \n",
      "epoch 22/1000, batch 1/2, loss 0.5212                                           \n",
      "epoch 22/1000, training rmse 1.1435                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 22/1000, validation rmse 1.5301, best validation rmse 1.1936              \n",
      "epoch 23/1000, batch 1/2, loss 0.5244                                           \n",
      "epoch 23/1000, training rmse 1.1471                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 23/1000, validation rmse 1.2035, best validation rmse 1.1936              \n",
      "epoch 24/1000, batch 1/2, loss 0.5338                                           \n",
      "epoch 24/1000, training rmse 1.1663                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 24/1000, validation rmse 1.4510, best validation rmse 1.1936              \n",
      "epoch 25/1000, batch 1/2, loss 0.5392                                           \n",
      "epoch 25/1000, training rmse 1.1589                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 25/1000, validation rmse 1.5612, best validation rmse 1.1936              \n",
      "epoch 26/1000, batch 1/2, loss 0.5094                                           \n",
      "epoch 26/1000, training rmse 1.0993                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 26/1000, validation rmse 1.7477, best validation rmse 1.1936              \n",
      "epoch 27/1000, batch 1/2, loss 0.4785                                           \n",
      "epoch 27/1000, training rmse 1.1429                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 27/1000, validation rmse 1.8852, best validation rmse 1.1936              \n",
      "epoch 28/1000, batch 1/2, loss 0.4697                                           \n",
      "epoch 28/1000, training rmse 1.1002                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 28/1000, validation rmse 1.7943, best validation rmse 1.1936              \n",
      "epoch 29/1000, batch 1/2, loss 0.4753                                           \n",
      "epoch 29/1000, training rmse 1.1025                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 29/1000, validation rmse 2.1518, best validation rmse 1.1936              \n",
      "epoch 30/1000, batch 1/2, loss 0.4371                                           \n",
      "epoch 30/1000, training rmse 1.0838                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 30/1000, validation rmse 1.9499, best validation rmse 1.1936              \n",
      "epoch 31/1000, batch 1/2, loss 0.4907                                           \n",
      "epoch 31/1000, training rmse 1.1185                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 31/1000, validation rmse 2.1220, best validation rmse 1.1936              \n",
      "epoch 32/1000, batch 1/2, loss 0.4850                                           \n",
      "epoch 32/1000, training rmse 1.1085                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 32/1000, validation rmse 2.1285, best validation rmse 1.1936              \n",
      "epoch 33/1000, batch 1/2, loss 0.4573                                           \n",
      "epoch 33/1000, training rmse 1.0787                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 33/1000, validation rmse 2.0838, best validation rmse 1.1936              \n",
      "epoch 34/1000, batch 1/2, loss 0.4616                                           \n",
      "epoch 34/1000, training rmse 1.0899                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 34/1000, validation rmse 2.1092, best validation rmse 1.1936              \n",
      "epoch 35/1000, batch 1/2, loss 0.4657                                           \n",
      "epoch 35/1000, training rmse 1.0670                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 35/1000, validation rmse 2.2496, best validation rmse 1.1936              \n",
      "epoch 36/1000, batch 1/2, loss 0.4263                                           \n",
      "epoch 36/1000, training rmse 1.0198                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 36/1000, validation rmse 2.2717, best validation rmse 1.1936              \n",
      "epoch 37/1000, batch 1/2, loss 0.4183                                           \n",
      "epoch 37/1000, training rmse 1.0609                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 37/1000, validation rmse 2.2422, best validation rmse 1.1936              \n",
      "epoch 38/1000, batch 1/2, loss 0.4283                                           \n",
      "epoch 38/1000, training rmse 0.9966                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 38/1000, validation rmse 2.1676, best validation rmse 1.1936              \n",
      "epoch 39/1000, batch 1/2, loss 0.4356                                           \n",
      "epoch 39/1000, training rmse 1.0636                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 39/1000, validation rmse 2.2790, best validation rmse 1.1936              \n",
      "epoch 40/1000, batch 1/2, loss 0.4239                                           \n",
      "epoch 40/1000, training rmse 1.0066                                             \n",
      "EarlyStopping counter: 19 out of 30                                             \n",
      "epoch 40/1000, validation rmse 2.0442, best validation rmse 1.1936              \n",
      "epoch 41/1000, batch 1/2, loss 0.4309                                           \n",
      "epoch 41/1000, training rmse 1.0460                                             \n",
      "EarlyStopping counter: 20 out of 30                                             \n",
      "epoch 41/1000, validation rmse 1.8639, best validation rmse 1.1936              \n",
      "epoch 42/1000, batch 1/2, loss 0.4554                                           \n",
      "epoch 42/1000, training rmse 1.0490                                             \n",
      "EarlyStopping counter: 21 out of 30                                             \n",
      "epoch 42/1000, validation rmse 2.0815, best validation rmse 1.1936              \n",
      "epoch 43/1000, batch 1/2, loss 0.4411                                           \n",
      "epoch 43/1000, training rmse 1.0629                                             \n",
      "EarlyStopping counter: 22 out of 30                                             \n",
      "epoch 43/1000, validation rmse 2.1425, best validation rmse 1.1936              \n",
      "epoch 44/1000, batch 1/2, loss 0.4190                                           \n",
      "epoch 44/1000, training rmse 1.0461                                             \n",
      "EarlyStopping counter: 23 out of 30                                             \n",
      "epoch 44/1000, validation rmse 1.6235, best validation rmse 1.1936              \n",
      "epoch 45/1000, batch 1/2, loss 0.4858                                           \n",
      "epoch 45/1000, training rmse 1.0748                                             \n",
      "EarlyStopping counter: 24 out of 30                                             \n",
      "epoch 45/1000, validation rmse 2.1098, best validation rmse 1.1936              \n",
      "epoch 46/1000, batch 1/2, loss 0.3908                                           \n",
      "epoch 46/1000, training rmse 1.0002                                             \n",
      "EarlyStopping counter: 25 out of 30                                             \n",
      "epoch 46/1000, validation rmse 1.7973, best validation rmse 1.1936              \n",
      "epoch 47/1000, batch 1/2, loss 0.4186                                           \n",
      "epoch 47/1000, training rmse 1.0254                                             \n",
      "EarlyStopping counter: 26 out of 30                                             \n",
      "epoch 47/1000, validation rmse 1.8151, best validation rmse 1.1936              \n",
      "epoch 48/1000, batch 1/2, loss 0.4225                                           \n",
      "epoch 48/1000, training rmse 1.0033                                             \n",
      "EarlyStopping counter: 27 out of 30                                             \n",
      "epoch 48/1000, validation rmse 1.7140, best validation rmse 1.1936              \n",
      "epoch 49/1000, batch 1/2, loss 0.4426                                           \n",
      "epoch 49/1000, training rmse 1.0281                                             \n",
      "EarlyStopping counter: 28 out of 30                                             \n",
      "epoch 49/1000, validation rmse 1.5210, best validation rmse 1.1936              \n",
      "epoch 50/1000, batch 1/2, loss 0.4091                                           \n",
      "epoch 50/1000, training rmse 1.0069                                             \n",
      "EarlyStopping counter: 29 out of 30                                             \n",
      "epoch 50/1000, validation rmse 1.9336, best validation rmse 1.1936              \n",
      "epoch 51/1000, batch 1/2, loss 0.4427                                           \n",
      "epoch 51/1000, training rmse 1.0287                                             \n",
      "EarlyStopping counter: 30 out of 30                                             \n",
      "epoch 51/1000, validation rmse 1.7109, best validation rmse 1.1936              \n",
      "test rmse 1.0523                                                                \n",
      " 60%|██████▌    | 3/5 [00:45<00:27, 13.88s/trial, best loss: 1.0110034942626953]INFO:hyperopt.tpe:build_posterior_wrapper took 0.004035 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 1.011003\n",
      "Created directory ../../../../regression_results/26                             \n",
      "For metric rmse, the lower the better                                           \n",
      "epoch 1/1000, batch 1/8, loss 2.6624                                            \n",
      "epoch 1/1000, training rmse 3.7764                                              \n",
      "epoch 1/1000, validation rmse 8.6915, best validation rmse 8.6915               \n",
      "epoch 2/1000, batch 1/8, loss 2.0121                                            \n",
      "epoch 2/1000, training rmse 2.2708                                              \n",
      "epoch 2/1000, validation rmse 3.7907, best validation rmse 3.7907               \n",
      "epoch 3/1000, batch 1/8, loss 1.7034                                            \n",
      "epoch 3/1000, training rmse 2.2879                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 3/1000, validation rmse 4.3467, best validation rmse 3.7907               \n",
      "epoch 4/1000, batch 1/8, loss 1.4731                                            \n",
      "epoch 4/1000, training rmse 1.9168                                              \n",
      "epoch 4/1000, validation rmse 1.7980, best validation rmse 1.7980               \n",
      "epoch 5/1000, batch 1/8, loss 0.7157                                            \n",
      "epoch 5/1000, training rmse 1.8147                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 5/1000, validation rmse 2.2427, best validation rmse 1.7980               \n",
      "epoch 6/1000, batch 1/8, loss 1.1558                                            \n",
      "epoch 6/1000, training rmse 1.8849                                              \n",
      "epoch 6/1000, validation rmse 1.6575, best validation rmse 1.6575               \n",
      "epoch 7/1000, batch 1/8, loss 0.9478                                            \n",
      "epoch 7/1000, training rmse 1.6923                                              \n",
      "epoch 7/1000, validation rmse 1.6431, best validation rmse 1.6431               \n",
      "epoch 8/1000, batch 1/8, loss 0.9518                                            \n",
      "epoch 8/1000, training rmse 1.6743                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 8/1000, validation rmse 1.6850, best validation rmse 1.6431               \n",
      "epoch 9/1000, batch 1/8, loss 0.9095                                            \n",
      "epoch 9/1000, training rmse 1.5550                                              \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 9/1000, validation rmse 1.8419, best validation rmse 1.6431               \n",
      "epoch 10/1000, batch 1/8, loss 1.0240                                           \n",
      "epoch 10/1000, training rmse 1.4681                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 10/1000, validation rmse 1.9625, best validation rmse 1.6431              \n",
      "epoch 11/1000, batch 1/8, loss 0.8316                                           \n",
      "epoch 11/1000, training rmse 1.6113                                             \n",
      "epoch 11/1000, validation rmse 1.5072, best validation rmse 1.5072              \n",
      "epoch 12/1000, batch 1/8, loss 0.7575                                           \n",
      "epoch 12/1000, training rmse 1.5491                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 12/1000, validation rmse 2.7274, best validation rmse 1.5072              \n",
      "epoch 13/1000, batch 1/8, loss 1.3240                                           \n",
      "epoch 13/1000, training rmse 1.6468                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 13/1000, validation rmse 2.5237, best validation rmse 1.5072              \n",
      "epoch 14/1000, batch 1/8, loss 0.8935                                           \n",
      "epoch 14/1000, training rmse 1.6489                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 14/1000, validation rmse 9.2878, best validation rmse 1.5072              \n",
      "epoch 15/1000, batch 1/8, loss 0.6971                                           \n",
      "epoch 15/1000, training rmse 1.7691                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 15/1000, validation rmse 6.4846, best validation rmse 1.5072              \n",
      "epoch 16/1000, batch 1/8, loss 0.9955                                           \n",
      "epoch 16/1000, training rmse 1.7455                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 16/1000, validation rmse 1.8333, best validation rmse 1.5072              \n",
      "epoch 17/1000, batch 1/8, loss 0.8052                                           \n",
      "epoch 17/1000, training rmse 1.6517                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 17/1000, validation rmse 7.7928, best validation rmse 1.5072              \n",
      "epoch 18/1000, batch 1/8, loss 1.3173                                           \n",
      "epoch 18/1000, training rmse 1.8796                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 18/1000, validation rmse 1.7628, best validation rmse 1.5072              \n",
      "epoch 19/1000, batch 1/8, loss 0.8799                                           \n",
      "epoch 19/1000, training rmse 1.6266                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 19/1000, validation rmse 5.3724, best validation rmse 1.5072              \n",
      "epoch 20/1000, batch 1/8, loss 1.6875                                           \n",
      "epoch 20/1000, training rmse 2.1520                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 20/1000, validation rmse 1.7543, best validation rmse 1.5072              \n",
      "epoch 21/1000, batch 1/8, loss 0.9788                                           \n",
      "epoch 21/1000, training rmse 1.9368                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 21/1000, validation rmse 2.4790, best validation rmse 1.5072              \n",
      "epoch 22/1000, batch 1/8, loss 0.9569                                           \n",
      "epoch 22/1000, training rmse 1.6264                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 22/1000, validation rmse 2.6834, best validation rmse 1.5072              \n",
      "epoch 23/1000, batch 1/8, loss 1.2678                                           \n",
      "epoch 23/1000, training rmse 1.8739                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 23/1000, validation rmse 2.4441, best validation rmse 1.5072              \n",
      "epoch 24/1000, batch 1/8, loss 1.0207                                           \n",
      "epoch 24/1000, training rmse 1.8102                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 24/1000, validation rmse 3.4658, best validation rmse 1.5072              \n",
      "epoch 25/1000, batch 1/8, loss 1.1291                                           \n",
      "epoch 25/1000, training rmse 1.6605                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 25/1000, validation rmse 1.7700, best validation rmse 1.5072              \n",
      "epoch 26/1000, batch 1/8, loss 0.9708                                           \n",
      "epoch 26/1000, training rmse 1.5515                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 26/1000, validation rmse 1.8431, best validation rmse 1.5072              \n",
      "epoch 27/1000, batch 1/8, loss 0.9929                                           \n",
      "epoch 27/1000, training rmse 1.7422                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 27/1000, validation rmse 2.8029, best validation rmse 1.5072              \n",
      "epoch 28/1000, batch 1/8, loss 0.7819                                           \n",
      "epoch 28/1000, training rmse 1.7394                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 28/1000, validation rmse 3.3034, best validation rmse 1.5072              \n",
      "epoch 29/1000, batch 1/8, loss 0.9790                                           \n",
      "epoch 29/1000, training rmse 1.6697                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 29/1000, validation rmse 3.4211, best validation rmse 1.5072              \n",
      "epoch 30/1000, batch 1/8, loss 1.2995                                           \n",
      "epoch 30/1000, training rmse 2.1080                                             \n",
      "EarlyStopping counter: 19 out of 30                                             \n",
      "epoch 30/1000, validation rmse 2.5067, best validation rmse 1.5072              \n",
      "epoch 31/1000, batch 1/8, loss 1.1978                                           \n",
      "epoch 31/1000, training rmse 1.9689                                             \n",
      "EarlyStopping counter: 20 out of 30                                             \n",
      "epoch 31/1000, validation rmse 5.5431, best validation rmse 1.5072              \n",
      "epoch 32/1000, batch 1/8, loss 1.0738                                           \n",
      "epoch 32/1000, training rmse 2.0093                                             \n",
      "EarlyStopping counter: 21 out of 30                                             \n",
      "epoch 32/1000, validation rmse 8.5996, best validation rmse 1.5072              \n",
      "epoch 33/1000, batch 1/8, loss 1.1767                                           \n",
      "epoch 33/1000, training rmse 1.8912                                             \n",
      "EarlyStopping counter: 22 out of 30                                             \n",
      "epoch 33/1000, validation rmse 2.6376, best validation rmse 1.5072              \n",
      "epoch 34/1000, batch 1/8, loss 1.4861                                           \n",
      "epoch 34/1000, training rmse 1.9892                                             \n",
      "EarlyStopping counter: 23 out of 30                                             \n",
      "epoch 34/1000, validation rmse 7.9527, best validation rmse 1.5072              \n",
      "epoch 35/1000, batch 1/8, loss 1.1041                                           \n",
      "epoch 35/1000, training rmse 1.7470                                             \n",
      "EarlyStopping counter: 24 out of 30                                             \n",
      "epoch 35/1000, validation rmse 3.6845, best validation rmse 1.5072              \n",
      "epoch 36/1000, batch 1/8, loss 1.0785                                           \n",
      "epoch 36/1000, training rmse 1.8655                                             \n",
      "EarlyStopping counter: 25 out of 30                                             \n",
      "epoch 36/1000, validation rmse 2.2815, best validation rmse 1.5072              \n",
      "epoch 37/1000, batch 1/8, loss 1.0525                                           \n",
      "epoch 37/1000, training rmse 1.7495                                             \n",
      "EarlyStopping counter: 26 out of 30                                             \n",
      "epoch 37/1000, validation rmse 1.6968, best validation rmse 1.5072              \n",
      "epoch 38/1000, batch 1/8, loss 1.0525                                           \n",
      "epoch 38/1000, training rmse 1.7859                                             \n",
      "EarlyStopping counter: 27 out of 30                                             \n",
      "epoch 38/1000, validation rmse 1.8723, best validation rmse 1.5072              \n",
      "epoch 39/1000, batch 1/8, loss 0.9597                                           \n",
      "epoch 39/1000, training rmse 1.7530                                             \n",
      "EarlyStopping counter: 28 out of 30                                             \n",
      "epoch 39/1000, validation rmse 1.5509, best validation rmse 1.5072              \n",
      "epoch 40/1000, batch 1/8, loss 0.9133                                           \n",
      "epoch 40/1000, training rmse 1.5650                                             \n",
      "EarlyStopping counter: 29 out of 30                                             \n",
      "epoch 40/1000, validation rmse 1.7604, best validation rmse 1.5072              \n",
      "epoch 41/1000, batch 1/8, loss 0.7857                                           \n",
      "epoch 41/1000, training rmse 1.6546                                             \n",
      "EarlyStopping counter: 30 out of 30                                             \n",
      "epoch 41/1000, validation rmse 3.3712, best validation rmse 1.5072              \n",
      "test rmse 1.5654                                                                \n",
      " 80%|████████▊  | 4/5 [00:55<00:12, 12.87s/trial, best loss: 1.0110034942626953]INFO:hyperopt.tpe:build_posterior_wrapper took 0.003891 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 1.011003\n",
      "Created directory ../../../../regression_results/27                             \n",
      "For metric rmse, the lower the better                                           \n",
      "epoch 1/1000, batch 1/15, loss 2.3985                                           \n",
      "epoch 1/1000, training rmse 2.2482                                              \n",
      "epoch 1/1000, validation rmse 3.5964, best validation rmse 3.5964               \n",
      "epoch 2/1000, batch 1/15, loss 1.4804                                           \n",
      "epoch 2/1000, training rmse 1.7609                                              \n",
      "epoch 2/1000, validation rmse 1.8222, best validation rmse 1.8222               \n",
      "epoch 3/1000, batch 1/15, loss 0.9088                                           \n",
      "epoch 3/1000, training rmse 1.6052                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 3/1000, validation rmse 2.0263, best validation rmse 1.8222               \n",
      "epoch 4/1000, batch 1/15, loss 0.7711                                           \n",
      "epoch 4/1000, training rmse 1.7706                                              \n",
      "epoch 4/1000, validation rmse 1.5614, best validation rmse 1.5614               \n",
      "epoch 5/1000, batch 1/15, loss 0.6812                                           \n",
      "epoch 5/1000, training rmse 1.7210                                              \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 5/1000, validation rmse 1.7406, best validation rmse 1.5614               \n",
      "epoch 6/1000, batch 1/15, loss 0.8962                                           \n",
      "epoch 6/1000, training rmse 1.6683                                              \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 6/1000, validation rmse 4.0120, best validation rmse 1.5614               \n",
      "epoch 7/1000, batch 1/15, loss 0.9587                                           \n",
      "epoch 7/1000, training rmse 1.6351                                              \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 7/1000, validation rmse 1.6057, best validation rmse 1.5614               \n",
      "epoch 8/1000, batch 1/15, loss 1.2296                                           \n",
      "epoch 8/1000, training rmse 1.7934                                              \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 8/1000, validation rmse 1.8445, best validation rmse 1.5614               \n",
      "epoch 9/1000, batch 1/15, loss 1.1364                                           \n",
      "epoch 9/1000, training rmse 1.6481                                              \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 9/1000, validation rmse 2.1128, best validation rmse 1.5614               \n",
      "epoch 10/1000, batch 1/15, loss 0.7481                                          \n",
      "epoch 10/1000, training rmse 1.7142                                             \n",
      "epoch 10/1000, validation rmse 1.5271, best validation rmse 1.5271              \n",
      "epoch 11/1000, batch 1/15, loss 0.9619                                          \n",
      "epoch 11/1000, training rmse 1.7405                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 11/1000, validation rmse 1.5715, best validation rmse 1.5271              \n",
      "epoch 12/1000, batch 1/15, loss 0.8283                                          \n",
      "epoch 12/1000, training rmse 1.7962                                             \n",
      "epoch 12/1000, validation rmse 1.5024, best validation rmse 1.5024              \n",
      "epoch 13/1000, batch 1/15, loss 0.6930                                          \n",
      "epoch 13/1000, training rmse 1.6232                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 13/1000, validation rmse 2.9171, best validation rmse 1.5024              \n",
      "epoch 14/1000, batch 1/15, loss 0.8723                                          \n",
      "epoch 14/1000, training rmse 1.6935                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 14/1000, validation rmse 1.7096, best validation rmse 1.5024              \n",
      "epoch 15/1000, batch 1/15, loss 0.9733                                          \n",
      "epoch 15/1000, training rmse 1.6392                                             \n",
      "epoch 15/1000, validation rmse 1.4897, best validation rmse 1.4897              \n",
      "epoch 16/1000, batch 1/15, loss 0.5946                                          \n",
      "epoch 16/1000, training rmse 1.5542                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 16/1000, validation rmse 1.6248, best validation rmse 1.4897              \n",
      "epoch 17/1000, batch 1/15, loss 1.0183                                          \n",
      "epoch 17/1000, training rmse 1.6342                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 17/1000, validation rmse 1.6171, best validation rmse 1.4897              \n",
      "epoch 18/1000, batch 1/15, loss 0.5602                                          \n",
      "epoch 18/1000, training rmse 1.6134                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 18/1000, validation rmse 2.0299, best validation rmse 1.4897              \n",
      "epoch 19/1000, batch 1/15, loss 0.9358                                          \n",
      "epoch 19/1000, training rmse 1.6981                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 19/1000, validation rmse 1.6494, best validation rmse 1.4897              \n",
      "epoch 20/1000, batch 1/15, loss 0.8393                                          \n",
      "epoch 20/1000, training rmse 1.7535                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 20/1000, validation rmse 1.7322, best validation rmse 1.4897              \n",
      "epoch 21/1000, batch 1/15, loss 1.0136                                          \n",
      "epoch 21/1000, training rmse 1.6537                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 21/1000, validation rmse 1.9756, best validation rmse 1.4897              \n",
      "epoch 22/1000, batch 1/15, loss 0.8905                                          \n",
      "epoch 22/1000, training rmse 1.5005                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 22/1000, validation rmse 1.9252, best validation rmse 1.4897              \n",
      "epoch 23/1000, batch 1/15, loss 1.0535                                          \n",
      "epoch 23/1000, training rmse 1.5347                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 23/1000, validation rmse 2.0592, best validation rmse 1.4897              \n",
      "epoch 24/1000, batch 1/15, loss 1.0066                                          \n",
      "epoch 24/1000, training rmse 1.8604                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 24/1000, validation rmse 2.0659, best validation rmse 1.4897              \n",
      "epoch 25/1000, batch 1/15, loss 0.9677                                          \n",
      "epoch 25/1000, training rmse 1.7612                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 25/1000, validation rmse 1.7823, best validation rmse 1.4897              \n",
      "epoch 26/1000, batch 1/15, loss 0.7748                                          \n",
      "epoch 26/1000, training rmse 1.7100                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 26/1000, validation rmse 2.4965, best validation rmse 1.4897              \n",
      "epoch 27/1000, batch 1/15, loss 0.7104                                          \n",
      "epoch 27/1000, training rmse 1.6188                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 27/1000, validation rmse 1.5779, best validation rmse 1.4897              \n",
      "epoch 28/1000, batch 1/15, loss 0.8879                                          \n",
      "epoch 28/1000, training rmse 1.6499                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 28/1000, validation rmse 1.6423, best validation rmse 1.4897              \n",
      "epoch 29/1000, batch 1/15, loss 0.7385                                          \n",
      "epoch 29/1000, training rmse 1.7180                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 29/1000, validation rmse 2.8732, best validation rmse 1.4897              \n",
      "epoch 30/1000, batch 1/15, loss 1.1991                                          \n",
      "epoch 30/1000, training rmse 1.6989                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 30/1000, validation rmse 1.6473, best validation rmse 1.4897              \n",
      "epoch 31/1000, batch 1/15, loss 0.8541                                          \n",
      "epoch 31/1000, training rmse 1.6157                                             \n",
      "epoch 31/1000, validation rmse 1.4647, best validation rmse 1.4647              \n",
      "epoch 32/1000, batch 1/15, loss 0.6872                                          \n",
      "epoch 32/1000, training rmse 1.5074                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 32/1000, validation rmse 2.1914, best validation rmse 1.4647              \n",
      "epoch 33/1000, batch 1/15, loss 0.7899                                          \n",
      "epoch 33/1000, training rmse 1.5527                                             \n",
      "epoch 33/1000, validation rmse 1.4053, best validation rmse 1.4053              \n",
      "epoch 34/1000, batch 1/15, loss 0.7893                                          \n",
      "epoch 34/1000, training rmse 1.6578                                             \n",
      "epoch 34/1000, validation rmse 1.3903, best validation rmse 1.3903              \n",
      "epoch 35/1000, batch 1/15, loss 0.6998                                          \n",
      "epoch 35/1000, training rmse 1.6571                                             \n",
      "EarlyStopping counter: 1 out of 30                                              \n",
      "epoch 35/1000, validation rmse 1.4910, best validation rmse 1.3903              \n",
      "epoch 36/1000, batch 1/15, loss 0.8101                                          \n",
      "epoch 36/1000, training rmse 1.4617                                             \n",
      "EarlyStopping counter: 2 out of 30                                              \n",
      "epoch 36/1000, validation rmse 1.4125, best validation rmse 1.3903              \n",
      "epoch 37/1000, batch 1/15, loss 0.7247                                          \n",
      "epoch 37/1000, training rmse 1.6042                                             \n",
      "EarlyStopping counter: 3 out of 30                                              \n",
      "epoch 37/1000, validation rmse 2.0636, best validation rmse 1.3903              \n",
      "epoch 38/1000, batch 1/15, loss 0.9049                                          \n",
      "epoch 38/1000, training rmse 1.6770                                             \n",
      "EarlyStopping counter: 4 out of 30                                              \n",
      "epoch 38/1000, validation rmse 1.8409, best validation rmse 1.3903              \n",
      "epoch 39/1000, batch 1/15, loss 0.7668                                          \n",
      "epoch 39/1000, training rmse 1.8092                                             \n",
      "EarlyStopping counter: 5 out of 30                                              \n",
      "epoch 39/1000, validation rmse 1.7754, best validation rmse 1.3903              \n",
      "epoch 40/1000, batch 1/15, loss 1.0069                                          \n",
      "epoch 40/1000, training rmse 1.6819                                             \n",
      "EarlyStopping counter: 6 out of 30                                              \n",
      "epoch 40/1000, validation rmse 1.6470, best validation rmse 1.3903              \n",
      "epoch 41/1000, batch 1/15, loss 0.8101                                          \n",
      "epoch 41/1000, training rmse 1.5907                                             \n",
      "EarlyStopping counter: 7 out of 30                                              \n",
      "epoch 41/1000, validation rmse 1.6677, best validation rmse 1.3903              \n",
      "epoch 42/1000, batch 1/15, loss 0.7774                                          \n",
      "epoch 42/1000, training rmse 1.5831                                             \n",
      "EarlyStopping counter: 8 out of 30                                              \n",
      "epoch 42/1000, validation rmse 1.5584, best validation rmse 1.3903              \n",
      "epoch 43/1000, batch 1/15, loss 0.9069                                          \n",
      "epoch 43/1000, training rmse 1.5470                                             \n",
      "EarlyStopping counter: 9 out of 30                                              \n",
      "epoch 43/1000, validation rmse 1.6778, best validation rmse 1.3903              \n",
      "epoch 44/1000, batch 1/15, loss 0.7898                                          \n",
      "epoch 44/1000, training rmse 1.5211                                             \n",
      "EarlyStopping counter: 10 out of 30                                             \n",
      "epoch 44/1000, validation rmse 1.5476, best validation rmse 1.3903              \n",
      "epoch 45/1000, batch 1/15, loss 1.0994                                          \n",
      "epoch 45/1000, training rmse 1.7300                                             \n",
      "EarlyStopping counter: 11 out of 30                                             \n",
      "epoch 45/1000, validation rmse 1.6456, best validation rmse 1.3903              \n",
      "epoch 46/1000, batch 1/15, loss 0.8765                                          \n",
      "epoch 46/1000, training rmse 1.6324                                             \n",
      "EarlyStopping counter: 12 out of 30                                             \n",
      "epoch 46/1000, validation rmse 1.5450, best validation rmse 1.3903              \n",
      "epoch 47/1000, batch 1/15, loss 0.8966                                          \n",
      "epoch 47/1000, training rmse 1.6210                                             \n",
      "EarlyStopping counter: 13 out of 30                                             \n",
      "epoch 47/1000, validation rmse 1.4624, best validation rmse 1.3903              \n",
      "epoch 48/1000, batch 1/15, loss 0.7697                                          \n",
      "epoch 48/1000, training rmse 1.5546                                             \n",
      "EarlyStopping counter: 14 out of 30                                             \n",
      "epoch 48/1000, validation rmse 1.6972, best validation rmse 1.3903              \n",
      "epoch 49/1000, batch 1/15, loss 0.8287                                          \n",
      "epoch 49/1000, training rmse 1.7278                                             \n",
      "EarlyStopping counter: 15 out of 30                                             \n",
      "epoch 49/1000, validation rmse 1.8012, best validation rmse 1.3903              \n",
      "epoch 50/1000, batch 1/15, loss 0.9324                                          \n",
      "epoch 50/1000, training rmse 1.7620                                             \n",
      "EarlyStopping counter: 16 out of 30                                             \n",
      "epoch 50/1000, validation rmse 2.3361, best validation rmse 1.3903              \n",
      "epoch 51/1000, batch 1/15, loss 0.7204                                          \n",
      "epoch 51/1000, training rmse 1.6514                                             \n",
      "EarlyStopping counter: 17 out of 30                                             \n",
      "epoch 51/1000, validation rmse 1.9002, best validation rmse 1.3903              \n",
      "epoch 52/1000, batch 1/15, loss 0.9624                                          \n",
      "epoch 52/1000, training rmse 1.6171                                             \n",
      "EarlyStopping counter: 18 out of 30                                             \n",
      "epoch 52/1000, validation rmse 1.5161, best validation rmse 1.3903              \n",
      "epoch 53/1000, batch 1/15, loss 1.0327                                          \n",
      "epoch 53/1000, training rmse 1.6624                                             \n",
      "EarlyStopping counter: 19 out of 30                                             \n",
      "epoch 53/1000, validation rmse 1.9685, best validation rmse 1.3903              \n",
      "epoch 54/1000, batch 1/15, loss 0.6894                                          \n",
      "epoch 54/1000, training rmse 1.5599                                             \n",
      "EarlyStopping counter: 20 out of 30                                             \n",
      "epoch 54/1000, validation rmse 1.6964, best validation rmse 1.3903              \n",
      "epoch 55/1000, batch 1/15, loss 1.1494                                          \n",
      "epoch 55/1000, training rmse 1.7453                                             \n",
      "EarlyStopping counter: 21 out of 30                                             \n",
      "epoch 55/1000, validation rmse 1.5543, best validation rmse 1.3903              \n",
      "epoch 56/1000, batch 1/15, loss 0.8218                                          \n",
      "epoch 56/1000, training rmse 1.5895                                             \n",
      "EarlyStopping counter: 22 out of 30                                             \n",
      "epoch 56/1000, validation rmse 2.2902, best validation rmse 1.3903              \n",
      "epoch 57/1000, batch 1/15, loss 0.9232                                          \n",
      "epoch 57/1000, training rmse 1.6406                                             \n",
      "EarlyStopping counter: 23 out of 30                                             \n",
      "epoch 57/1000, validation rmse 1.7692, best validation rmse 1.3903              \n",
      "epoch 58/1000, batch 1/15, loss 1.1115                                          \n",
      "epoch 58/1000, training rmse 1.6032                                             \n",
      "EarlyStopping counter: 24 out of 30                                             \n",
      "epoch 58/1000, validation rmse 1.8180, best validation rmse 1.3903              \n",
      "epoch 59/1000, batch 1/15, loss 1.3034                                          \n",
      "epoch 59/1000, training rmse 1.6896                                             \n",
      "EarlyStopping counter: 25 out of 30                                             \n",
      "epoch 59/1000, validation rmse 1.8521, best validation rmse 1.3903              \n",
      "epoch 60/1000, batch 1/15, loss 0.8276                                          \n",
      "epoch 60/1000, training rmse 1.6870                                             \n",
      "EarlyStopping counter: 26 out of 30                                             \n",
      "epoch 60/1000, validation rmse 1.9586, best validation rmse 1.3903              \n",
      "epoch 61/1000, batch 1/15, loss 1.0214                                          \n",
      "epoch 61/1000, training rmse 1.6138                                             \n",
      "EarlyStopping counter: 27 out of 30                                             \n",
      "epoch 61/1000, validation rmse 2.9582, best validation rmse 1.3903              \n",
      "epoch 62/1000, batch 1/15, loss 1.0219                                          \n",
      "epoch 62/1000, training rmse 1.6259                                             \n",
      "EarlyStopping counter: 28 out of 30                                             \n",
      "epoch 62/1000, validation rmse 1.3943, best validation rmse 1.3903              \n",
      "epoch 63/1000, batch 1/15, loss 0.6743                                          \n",
      "epoch 63/1000, training rmse 1.6497                                             \n",
      "EarlyStopping counter: 29 out of 30                                             \n",
      "epoch 63/1000, validation rmse 2.3827, best validation rmse 1.3903              \n",
      "epoch 64/1000, batch 1/15, loss 0.8351                                          \n",
      "epoch 64/1000, training rmse 1.6666                                             \n",
      "EarlyStopping counter: 30 out of 30                                             \n",
      "epoch 64/1000, validation rmse 1.8863, best validation rmse 1.3903              \n",
      "test rmse 1.5018                                                                \n",
      "100%|███████████| 5/5 [01:06<00:00, 13.25s/trial, best loss: 1.0110034942626953]\n"
     ]
    }
   ],
   "source": [
    "# With Hyper Parameter Search\n",
    "%cd ../csv_data_configuration/\n",
    "!python regression_train.py -ne 5 -c ../../../../ESOL/delaney-processed.csv -sc 'smiles' -t 'measured log solubility in mols per litre' -me rmse -nw 0 -p ../../../../regression_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ToDo \n",
    "テストセット用CSVファイルを別に作って残しといてそれで推論"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Train your own models using Amazon SageMaker Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'dgllifesci/esol/dataset'\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/Yusmoris-dgllifesci-handson\n",
      "upload: ESOL/delaney-processed.csv to s3://sagemaker-ap-northeast-1-233488627969/dgllifesci/esol/dataset/delaney-processed.csv\n",
      "2022-12-13 04:26:01      96699 delaney-processed.csv\n"
     ]
    }
   ],
   "source": [
    "# データをS3にアップロード\n",
    "%cd ../\n",
    "!aws s3 cp ./ESOL/delaney-processed.csv s3://{bucket}/{prefix}/delaney-processed.csv\n",
    "!aws s3 ls s3://{bucket}/{prefix}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input = sagemaker.inputs.TrainingInput(s3_data=f's3://{bucket}/{prefix}/delaney-processed.csv', content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dgl-cu101 -f https://data.dgl.ai/wheels/repo.html\n",
      "dgllife\n",
      "rdkit-pypi\n"
     ]
    }
   ],
   "source": [
    "!touch dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt\n",
    "!echo \"dgl-cu101 -f https://data.dgl.ai/wheels/repo.html\\ndgllife\\nrdkit-pypi\" > dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt\n",
    "!cat dgl-lifesci/examples/property_prediction/csv_data_configuration/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "# import json\n",
    "# # JSON encode hyperparameters\n",
    "# def json_encode_hyperparameters(hyperparameters):\n",
    "#     return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "# hyperparameters = json_encode_hyperparameters(\n",
    "#     {\n",
    "#         'dataset':'Tox21',\n",
    "#         'model':'GCN',\n",
    "#         'featurizer-type':'canonical',\n",
    "#         'sagemaker_program':'classification.py',\n",
    "#         'sagemaker_submit_directory':inputs\n",
    "#     }\n",
    "# )\n",
    "\n",
    "hyperparameters = {\n",
    "    'csv-name': 'delaney-processed.csv',\n",
    "    'model':'GCN',\n",
    "    'atom-featurizer-type':'canonical',\n",
    "    'smiles-column':'smiles',\n",
    "    'task-names':\"measured log solubility in mols per litre\",\n",
    "    'metric':'rmse',\n",
    "    'num-workers': 0,\n",
    "    'num-evals': 10,   \n",
    "}\n",
    "\n",
    "# Create estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"regression_train_sagemaker.py\",\n",
    "    source_dir=\"./csv_data_configuration/\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    hyperparameters=hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-16 08:08:42 Starting - Starting the training job...\n",
      "2022-12-16 08:09:07 Starting - Preparing the instances for trainingProfilerReport-1671178121: InProgress\n",
      ".........\n",
      "2022-12-16 08:10:29 Downloading - Downloading input data...\n",
      "2022-12-16 08:11:07 Training - Downloading the training image...\n",
      "2022-12-16 08:11:27 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:27,815 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:27,818 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:27,828 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:27,831 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:28,184 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting dgl-cu101\n",
      "  Downloading dgl_cu101-0.6.1-cp36-cp36m-manylinux1_x86_64.whl (36.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting dgllife\n",
      "  Downloading dgllife-0.3.0-py3-none-any.whl (220 kB)\u001b[0m\n",
      "\u001b[34mCollecting rdkit-pypi\n",
      "  Downloading rdkit_pypi-2021.9.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (2.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.6/site-packages (from dgl-cu101->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.1->dgl-cu101->-r requirements.txt (line 1)) (4.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.19.0->dgl-cu101->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (4.51.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<1.0,>=0.22.2 in /opt/conda/lib/python3.6/site-packages (from dgllife->-r requirements.txt (line 2)) (0.24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn<1.0,>=0.22.2->dgllife->-r requirements.txt (line 2)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from rdkit-pypi->-r requirements.txt (line 3)) (8.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife->-r requirements.txt (line 2)) (0.18.2)\u001b[0m\n",
      "\u001b[34mCollecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from hyperopt->dgllife->-r requirements.txt (line 2)) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife->-r requirements.txt (line 2)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->dgllife->-r requirements.txt (line 2)) (2021.1)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: py4j, cloudpickle, hyperopt, rdkit-pypi, dgllife, dgl-cu101\u001b[0m\n",
      "\u001b[34mSuccessfully installed cloudpickle-2.2.0 dgl-cu101-0.6.1 dgllife-0.3.0 hyperopt-0.2.7 py4j-0.10.9.7 rdkit-pypi-2021.9.4\u001b[0m\n",
      "\u001b[34mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\u001b[0m\n",
      "\u001b[34mdistutils: /opt/conda/include/python3.6m/UNKNOWN\u001b[0m\n",
      "\u001b[34msysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[34mWARNING: Additional context:\u001b[0m\n",
      "\u001b[34muser = False\u001b[0m\n",
      "\u001b[34mhome = None\u001b[0m\n",
      "\u001b[34mroot = None\u001b[0m\n",
      "\u001b[34mprefix = None\u001b[0m\n",
      "\u001b[34mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\u001b[0m\n",
      "\u001b[34mdistutils: /opt/conda/include/python3.6m/UNKNOWN\u001b[0m\n",
      "\u001b[34msysconfig: /opt/conda/include/python3.6m\u001b[0m\n",
      "\u001b[34mWARNING: Additional context:\u001b[0m\n",
      "\u001b[34muser = False\u001b[0m\n",
      "\u001b[34mhome = None\u001b[0m\n",
      "\u001b[34mroot = None\u001b[0m\n",
      "\u001b[34mprefix = None\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:34,767 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:34,781 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:34,793 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:34,805 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"atom-featurizer-type\": \"canonical\",\n",
      "        \"csv-name\": \"delaney-processed.csv\",\n",
      "        \"metric\": \"rmse\",\n",
      "        \"model\": \"GCN\",\n",
      "        \"num-evals\": 10,\n",
      "        \"num-workers\": 0,\n",
      "        \"smiles-column\": \"smiles\",\n",
      "        \"task-names\": \"measured log solubility in mols per litre\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-12-16-08-08-40-798\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-08-08-40-798/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"regression_train_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"regression_train_sagemaker.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"atom-featurizer-type\":\"canonical\",\"csv-name\":\"delaney-processed.csv\",\"metric\":\"rmse\",\"model\":\"GCN\",\"num-evals\":10,\"num-workers\":0,\"smiles-column\":\"smiles\",\"task-names\":\"measured log solubility in mols per litre\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=regression_train_sagemaker.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=regression_train_sagemaker\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-08-08-40-798/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"atom-featurizer-type\":\"canonical\",\"csv-name\":\"delaney-processed.csv\",\"metric\":\"rmse\",\"model\":\"GCN\",\"num-evals\":10,\"num-workers\":0,\"smiles-column\":\"smiles\",\"task-names\":\"measured log solubility in mols per litre\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-12-16-08-08-40-798\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-233488627969/pytorch-training-2022-12-16-08-08-40-798/source/sourcedir.tar.gz\",\"module_name\":\"regression_train_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"regression_train_sagemaker.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--atom-featurizer-type\",\"canonical\",\"--csv-name\",\"delaney-processed.csv\",\"--metric\",\"rmse\",\"--model\",\"GCN\",\"--num-evals\",\"10\",\"--num-workers\",\"0\",\"--smiles-column\",\"smiles\",\"--task-names\",\"measured log solubility in mols per litre\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ATOM-FEATURIZER-TYPE=canonical\u001b[0m\n",
      "\u001b[34mSM_HP_CSV-NAME=delaney-processed.csv\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC=rmse\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=GCN\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-EVALS=10\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-WORKERS=0\u001b[0m\n",
      "\u001b[34mSM_HP_SMILES-COLUMN=smiles\u001b[0m\n",
      "\u001b[34mSM_HP_TASK-NAMES=measured log solubility in mols per litre\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 regression_train_sagemaker.py --atom-featurizer-type canonical --csv-name delaney-processed.csv --metric rmse --model GCN --num-evals 10 --num-workers 0 --smiles-column smiles --task-names measured log solubility in mols per litre\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"regression_train_sagemaker.py\", line 14, in <module>\n",
      "    from dgllife.utils import Meter, EarlyStopping\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/__init__.py\", line 9, in <module>\n",
      "    from . import model\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/__init__.py\", line 6, in <module>\n",
      "    from .gnn import *\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/__init__.py\", line 8, in <module>\n",
      "    from .attentivefp import *\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/attentivefp.py\", line 9, in <module>\n",
      "    import dgl.function as fn\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/__init__.py\", line 13, in <module>\n",
      "    from .backend import load_backend, backend_name\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/backend/__init__.py\", line 95, in <module>\n",
      "    load_backend(get_preferred_backend())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/backend/__init__.py\", line 41, in load_backend\n",
      "    from .._ffi.base import load_tensor_adapter # imports DGL C library\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/_ffi/base.py\", line 44, in <module>\n",
      "    _LIB, _LIB_NAME, _DIR_NAME = _load_lib()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/_ffi/base.py\", line 34, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0])\n",
      "  File \"/opt/conda/lib/python3.6/ctypes/__init__.py\", line 348, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\u001b[0m\n",
      "\u001b[34mOSError: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-12-16 08:11:35,841 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.6 regression_train_sagemaker.py --atom-featurizer-type canonical --csv-name delaney-processed.csv --metric rmse --model GCN --num-evals 10 --num-workers 0 --smiles-column smiles --task-names measured log solubility in mols per litre\"\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"regression_train_sagemaker.py\", line 14, in <module>\n",
      "    from dgllife.utils import Meter, EarlyStopping\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/__init__.py\", line 9, in <module>\n",
      "    from . import model\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/__init__.py\", line 6, in <module>\n",
      "    from .gnn import *\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/__init__.py\", line 8, in <module>\n",
      "    from .attentivefp import *\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/attentivefp.py\", line 9, in <module>\n",
      "    import dgl.function as fn\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/__init__.py\", line 13, in <module>\n",
      "    from .backend import load_backend, backend_name\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/backend/__init__.py\", line 95, in <module>\n",
      "    load_backend(get_preferred_backend())\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/backend/__init__.py\", line 41, in load_backend\n",
      "    from .._ffi.base import load_tensor_adapter # imports DGL C library\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/_ffi/base.py\", line 44, in <module>\n",
      "    _LIB, _LIB_NAME, _DIR_NAME = _load_lib()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/dgl/_ffi/base.py\", line 34, in _load_lib\n",
      "    lib = ctypes.CDLL(lib_path[0])\n",
      "  File \"/opt/conda/lib/python3.6/ctypes/__init__.py\", line 348, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\u001b[0m\n",
      "\u001b[34mOSError: libcudart.so.10.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\n",
      "2022-12-16 08:12:10 Uploading - Uploading generated training model\n",
      "2022-12-16 08:12:10 Failed - Training job failed\n",
      "ProfilerReport-1671178121: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-training-2022-12-16-08-08-40-798: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 regression_train_sagemaker.py --atom-featurizer-type canonical --csv-name delaney-processed.csv --metric rmse --model GCN --num-evals 10 --num-workers 0 --smiles-column smiles --task-names measured log solubility in mols per litre\"\nTraceback (most recent call last):\n  File \"regression_train_sagemaker.py\", line 14, in <module>\n    from dgllife.utils import Meter, EarlyStopping\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/__init__.py\", line 9, in <module>\n    from . import model\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/__init__.py\", line 6, in <module>\n    from .gnn import *\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/__init__.py\", line 8, in <module>\n    from .attentivefp import *\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/attentivefp.py\", line 9, in <module>\n    import dgl.function as fn\n  File \"/opt/conda/lib/python3.6/site-packages/dgl/__init__.py\", line 13, in <",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-924029dea522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 学習を開始\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms3_input\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3662\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3663\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3231\u001b[0m                 ),\n\u001b[1;32m   3232\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3233\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3234\u001b[0m             )\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-training-2022-12-16-08-08-40-798: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 regression_train_sagemaker.py --atom-featurizer-type canonical --csv-name delaney-processed.csv --metric rmse --model GCN --num-evals 10 --num-workers 0 --smiles-column smiles --task-names measured log solubility in mols per litre\"\nTraceback (most recent call last):\n  File \"regression_train_sagemaker.py\", line 14, in <module>\n    from dgllife.utils import Meter, EarlyStopping\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/__init__.py\", line 9, in <module>\n    from . import model\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/__init__.py\", line 6, in <module>\n    from .gnn import *\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/__init__.py\", line 8, in <module>\n    from .attentivefp import *\n  File \"/opt/conda/lib/python3.6/site-packages/dgllife/model/gnn/attentivefp.py\", line 9, in <module>\n    import dgl.function as fn\n  File \"/opt/conda/lib/python3.6/site-packages/dgl/__init__.py\", line 13, in <"
     ]
    }
   ],
   "source": [
    "# 学習を開始\n",
    "estimator.fit({'train':s3_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pytorch-training-2022-12-13-08-19-05-161'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.latest_training_job.job_name\n",
    "# !aws s3 cp {estimator.output_path}{estimator.latest_training_job.job_name}/output/model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Train your own models using Amazon SageMaker Training Job with Custom Container (※ Optional) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### メモ\n",
    "- requirementの`RDKit 2018.09.3`がconda installでないとinstallできないので、document通りに確実に動く環境を整えるならこっち（のはず）。\n",
    "- ただし`pip install rdkit-pypl`でも対応できる(2022年12月現在)。version 2018.09.3のものはサポートされていないが、dglaiの方のハンズオンではこれで対応している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "SageMakerで学習を実行するにあたり必要なライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "docker_name=sagemaker-dgllifesci-py36\n",
    "sm-docker build . -f ./container/Dockerfile --repository $docker_name:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf source.tar.gz utils.py classification.py ./configures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-ap-northeast-1-233488627969/dgl-lifesci/property_prediction/code/source.tar.gz\n"
     ]
    }
   ],
   "source": [
    "prefix = 'dgl-lifesci/property_prediction/code'\n",
    "inputs = sess.upload_data(path='./source.tar.gz', bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-28 16:15:05 Starting - Starting the training job...\n",
      "2022-07-28 16:15:29 Starting - Preparing the instances for trainingProfilerReport-1659024904: InProgress\n",
      "......\n",
      "2022-07-28 16:16:33 Downloading - Downloading input data...\n",
      "2022-07-28 16:16:49 Training - Downloading the training image.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:45,869 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:45,871 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:45,881 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:45,885 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:46,228 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:46,240 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:46,252 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-07-28 16:17:46,262 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataset\": \"Tox21\",\n",
      "        \"featurizer-type\": \"canonical\",\n",
      "        \"model\": \"GCN\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-dgllifesci-py36-2022-07-28-16-15-04-978\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-233488627969/dgl-lifesci/property_prediction/code/source.tar.gz\",\n",
      "    \"module_name\": \"classification\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"classification.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dataset\":\"Tox21\",\"featurizer-type\":\"canonical\",\"model\":\"GCN\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=classification.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=classification\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-233488627969/dgl-lifesci/property_prediction/code/source.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataset\":\"Tox21\",\"featurizer-type\":\"canonical\",\"model\":\"GCN\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-dgllifesci-py36-2022-07-28-16-15-04-978\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-233488627969/dgl-lifesci/property_prediction/code/source.tar.gz\",\"module_name\":\"classification\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"classification.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dataset\",\"Tox21\",\"--featurizer-type\",\"canonical\",\"--model\",\"GCN\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET=Tox21\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURIZER-TYPE=canonical\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=GCN\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 classification.py --dataset Tox21 --featurizer-type canonical --model GCN\u001b[0m\n",
      "\u001b[34m<dgllife.utils.featurizers.CanonicalAtomFeaturizer object at 0x7f473d69b898>\u001b[0m\n",
      "\u001b[34mCreated directory classification_results\u001b[0m\n",
      "\u001b[34mDownloading /root/.dgl/tox21.csv.gz from https://data.dgl.ai/dataset/tox21.csv.gz...\u001b[0m\n",
      "\u001b[34mProcessing dgl graphs from scratch...\u001b[0m\n",
      "\u001b[34mProcessing molecule 1000/7831\u001b[0m\n",
      "\u001b[34mProcessing molecule 2000/7831\u001b[0m\n",
      "\u001b[34mProcessing molecule 3000/7831\u001b[0m\n",
      "\n",
      "2022-07-28 16:17:49 Training - Training image download completed. Training in progress.\u001b[34mProcessing molecule 4000/7831\u001b[0m\n",
      "\u001b[34mProcessing molecule 5000/7831\u001b[0m\n",
      "\u001b[34mProcessing molecule 6000/7831\u001b[0m\n",
      "\u001b[34mProcessing molecule 7000/7831\u001b[0m\n",
      "\u001b[34mStart initializing RDKit molecule instances...\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 1000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 2000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 3000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 4000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 5000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 6000/7831\u001b[0m\n",
      "\u001b[34mCreating RDKit molecule instance 7000/7831\u001b[0m\n",
      "\u001b[34mStart computing Bemis-Murcko scaffolds.\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 1000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 2000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 3000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 4000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 5000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 6000/7831\u001b[0m\n",
      "\u001b[34mComputing Bemis-Murcko for compound 7000/7831\u001b[0m\n",
      "\u001b[34m{'batch_size': 32, 'batchnorm': False, 'dropout': 0.18118350615245202, 'gnn_hidden_feats': 64, 'lr': 0.0008963957671468941, 'num_gnn_layers': 3, 'patience': 3, 'predictor_hidden_feats': 16, 'residual': False, 'weight_decay': 1.5353642545259472e-05}\u001b[0m\n",
      "\u001b[34mFor metric roc_auc_score, the higher the better\u001b[0m\n",
      "\u001b[34m[2022-07-28 16:18:06.048 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-07-28 16:18:06.168 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 1/196, loss 0.5884\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 21/196, loss 0.5982\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 41/196, loss 0.5859\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 61/196, loss 0.5792\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 81/196, loss 0.5550\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 101/196, loss 0.4959\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 121/196, loss 0.4762\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 141/196, loss 0.5039\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 161/196, loss 0.4476\u001b[0m\n",
      "\u001b[34mepoch 1/1000, batch 181/196, loss 0.4204\u001b[0m\n",
      "\u001b[34mepoch 1/1000, training roc_auc_score 0.6156\u001b[0m\n",
      "\u001b[34mepoch 1/1000, validation roc_auc_score 0.6753, best validation roc_auc_score 0.6753\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 1/196, loss 0.3939\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 21/196, loss 0.3901\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 41/196, loss 0.3535\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 61/196, loss 0.3268\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 81/196, loss 0.2997\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 101/196, loss 0.2499\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 121/196, loss 0.2338\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 141/196, loss 0.2814\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 161/196, loss 0.2268\u001b[0m\n",
      "\u001b[34mepoch 2/1000, batch 181/196, loss 0.2237\u001b[0m\n",
      "\u001b[34mepoch 2/1000, training roc_auc_score 0.6635\u001b[0m\n",
      "\u001b[34mepoch 2/1000, validation roc_auc_score 0.7033, best validation roc_auc_score 0.7033\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 1/196, loss 0.2143\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 21/196, loss 0.2128\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 41/196, loss 0.2071\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 61/196, loss 0.1697\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 81/196, loss 0.2215\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 101/196, loss 0.1769\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 121/196, loss 0.1876\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 141/196, loss 0.1933\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 161/196, loss 0.1387\u001b[0m\n",
      "\u001b[34mepoch 3/1000, batch 181/196, loss 0.2073\u001b[0m\n",
      "\u001b[34mepoch 3/1000, training roc_auc_score 0.7173\u001b[0m\n",
      "\u001b[34mepoch 3/1000, validation roc_auc_score 0.7167, best validation roc_auc_score 0.7167\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 1/196, loss 0.2252\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 21/196, loss 0.1794\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 41/196, loss 0.2070\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 61/196, loss 0.2759\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 81/196, loss 0.2547\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 101/196, loss 0.1514\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 121/196, loss 0.1690\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 141/196, loss 0.1725\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 161/196, loss 0.1404\u001b[0m\n",
      "\u001b[34mepoch 4/1000, batch 181/196, loss 0.2586\u001b[0m\n",
      "\u001b[34mepoch 4/1000, training roc_auc_score 0.7366\u001b[0m\n",
      "\u001b[34mepoch 4/1000, validation roc_auc_score 0.7178, best validation roc_auc_score 0.7178\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 1/196, loss 0.1902\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 21/196, loss 0.1920\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 41/196, loss 0.2745\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 61/196, loss 0.1160\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 81/196, loss 0.1525\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 101/196, loss 0.1999\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 121/196, loss 0.2059\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 141/196, loss 0.2379\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 161/196, loss 0.2077\u001b[0m\n",
      "\u001b[34mepoch 5/1000, batch 181/196, loss 0.2304\u001b[0m\n",
      "\u001b[34mepoch 5/1000, training roc_auc_score 0.7454\u001b[0m\n",
      "\u001b[34mepoch 5/1000, validation roc_auc_score 0.7276, best validation roc_auc_score 0.7276\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 1/196, loss 0.1809\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 21/196, loss 0.1428\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 41/196, loss 0.1519\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 61/196, loss 0.1914\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 81/196, loss 0.1973\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 101/196, loss 0.1534\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 121/196, loss 0.1229\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 141/196, loss 0.1271\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 161/196, loss 0.1451\u001b[0m\n",
      "\u001b[34mepoch 6/1000, batch 181/196, loss 0.2255\u001b[0m\n",
      "\u001b[34mepoch 6/1000, training roc_auc_score 0.7614\u001b[0m\n",
      "\u001b[34mepoch 6/1000, validation roc_auc_score 0.7339, best validation roc_auc_score 0.7339\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 1/196, loss 0.1443\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 21/196, loss 0.1642\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 41/196, loss 0.1371\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 61/196, loss 0.1213\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 81/196, loss 0.1458\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 101/196, loss 0.2455\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 121/196, loss 0.1675\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 141/196, loss 0.1888\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 161/196, loss 0.1848\u001b[0m\n",
      "\u001b[34mepoch 7/1000, batch 181/196, loss 0.1906\u001b[0m\n",
      "\u001b[34mepoch 7/1000, training roc_auc_score 0.7760\u001b[0m\n",
      "\u001b[34mepoch 7/1000, validation roc_auc_score 0.7492, best validation roc_auc_score 0.7492\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 1/196, loss 0.1412\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 21/196, loss 0.2027\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 41/196, loss 0.1464\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 61/196, loss 0.1460\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 81/196, loss 0.1488\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 101/196, loss 0.1988\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 121/196, loss 0.1418\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 141/196, loss 0.1180\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 161/196, loss 0.1830\u001b[0m\n",
      "\u001b[34mepoch 8/1000, batch 181/196, loss 0.1648\u001b[0m\n",
      "\u001b[34mepoch 8/1000, training roc_auc_score 0.7807\u001b[0m\n",
      "\u001b[34mepoch 8/1000, validation roc_auc_score 0.7514, best validation roc_auc_score 0.7514\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 1/196, loss 0.1962\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 21/196, loss 0.1165\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 41/196, loss 0.1430\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 61/196, loss 0.2331\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 81/196, loss 0.1430\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 101/196, loss 0.1736\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 121/196, loss 0.2181\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 141/196, loss 0.1268\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 161/196, loss 0.1338\u001b[0m\n",
      "\u001b[34mepoch 9/1000, batch 181/196, loss 0.1787\u001b[0m\n",
      "\u001b[34mepoch 9/1000, training roc_auc_score 0.7889\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34mepoch 9/1000, validation roc_auc_score 0.7514, best validation roc_auc_score 0.7514\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 1/196, loss 0.1143\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 21/196, loss 0.2044\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 41/196, loss 0.1428\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 61/196, loss 0.1672\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 81/196, loss 0.1363\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 101/196, loss 0.1205\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 121/196, loss 0.2137\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 141/196, loss 0.1896\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 161/196, loss 0.1805\u001b[0m\n",
      "\u001b[34mepoch 10/1000, batch 181/196, loss 0.1203\u001b[0m\n",
      "\u001b[34mepoch 10/1000, training roc_auc_score 0.7918\u001b[0m\n",
      "\u001b[34mepoch 10/1000, validation roc_auc_score 0.7651, best validation roc_auc_score 0.7651\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 1/196, loss 0.2096\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 21/196, loss 0.1224\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 41/196, loss 0.2409\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 61/196, loss 0.1545\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 81/196, loss 0.1635\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 101/196, loss 0.1716\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 121/196, loss 0.1232\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 141/196, loss 0.1364\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 161/196, loss 0.2042\u001b[0m\n",
      "\u001b[34mepoch 11/1000, batch 181/196, loss 0.1366\u001b[0m\n",
      "\u001b[34mepoch 11/1000, training roc_auc_score 0.8014\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34mepoch 11/1000, validation roc_auc_score 0.7645, best validation roc_auc_score 0.7651\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 1/196, loss 0.1390\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 21/196, loss 0.1114\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 41/196, loss 0.1312\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 61/196, loss 0.2097\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 81/196, loss 0.1738\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 101/196, loss 0.1541\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 121/196, loss 0.1289\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 141/196, loss 0.1672\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 161/196, loss 0.1570\u001b[0m\n",
      "\u001b[34mepoch 12/1000, batch 181/196, loss 0.1351\u001b[0m\n",
      "\u001b[34mepoch 12/1000, training roc_auc_score 0.8036\u001b[0m\n",
      "\u001b[34mepoch 12/1000, validation roc_auc_score 0.7685, best validation roc_auc_score 0.7685\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 1/196, loss 0.1804\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 21/196, loss 0.1254\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 41/196, loss 0.1339\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 61/196, loss 0.1688\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 81/196, loss 0.1178\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 101/196, loss 0.2009\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 121/196, loss 0.0816\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 141/196, loss 0.2041\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 161/196, loss 0.2282\u001b[0m\n",
      "\u001b[34mepoch 13/1000, batch 181/196, loss 0.2211\u001b[0m\n",
      "\u001b[34mepoch 13/1000, training roc_auc_score 0.8135\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34mepoch 13/1000, validation roc_auc_score 0.7645, best validation roc_auc_score 0.7685\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 1/196, loss 0.1286\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 21/196, loss 0.1312\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 41/196, loss 0.2172\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 61/196, loss 0.2036\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 81/196, loss 0.1376\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 101/196, loss 0.1083\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 121/196, loss 0.1463\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 141/196, loss 0.1967\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 161/196, loss 0.1636\u001b[0m\n",
      "\u001b[34mepoch 14/1000, batch 181/196, loss 0.1108\u001b[0m\n",
      "\u001b[34mepoch 14/1000, training roc_auc_score 0.8163\u001b[0m\n",
      "\u001b[34mepoch 14/1000, validation roc_auc_score 0.7719, best validation roc_auc_score 0.7719\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 1/196, loss 0.1587\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 21/196, loss 0.1576\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 41/196, loss 0.1489\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 61/196, loss 0.1937\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 81/196, loss 0.1927\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 101/196, loss 0.1865\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 121/196, loss 0.1268\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 141/196, loss 0.1342\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 161/196, loss 0.1330\u001b[0m\n",
      "\u001b[34mepoch 15/1000, batch 181/196, loss 0.1178\u001b[0m\n",
      "\u001b[34mepoch 15/1000, training roc_auc_score 0.8179\u001b[0m\n",
      "\u001b[34mepoch 15/1000, validation roc_auc_score 0.7769, best validation roc_auc_score 0.7769\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 1/196, loss 0.1926\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 21/196, loss 0.1302\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 41/196, loss 0.1814\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 61/196, loss 0.1482\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 81/196, loss 0.1472\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 101/196, loss 0.2085\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 121/196, loss 0.1396\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 141/196, loss 0.2051\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 161/196, loss 0.1400\u001b[0m\n",
      "\u001b[34mepoch 16/1000, batch 181/196, loss 0.1240\u001b[0m\n",
      "\u001b[34mepoch 16/1000, training roc_auc_score 0.8193\u001b[0m\n",
      "\u001b[34mepoch 16/1000, validation roc_auc_score 0.7793, best validation roc_auc_score 0.7793\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 1/196, loss 0.1390\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 21/196, loss 0.2348\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 41/196, loss 0.1493\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 61/196, loss 0.1453\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 81/196, loss 0.1681\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 101/196, loss 0.1381\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 121/196, loss 0.2303\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 141/196, loss 0.1939\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 161/196, loss 0.1193\u001b[0m\n",
      "\u001b[34mepoch 17/1000, batch 181/196, loss 0.2192\u001b[0m\n",
      "\u001b[34mepoch 17/1000, training roc_auc_score 0.8274\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34mepoch 17/1000, validation roc_auc_score 0.7635, best validation roc_auc_score 0.7793\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 1/196, loss 0.2221\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 21/196, loss 0.1879\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 41/196, loss 0.1562\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 61/196, loss 0.1604\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 81/196, loss 0.1283\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 101/196, loss 0.1216\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 121/196, loss 0.2593\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 141/196, loss 0.1653\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 161/196, loss 0.1504\u001b[0m\n",
      "\u001b[34mepoch 18/1000, batch 181/196, loss 0.1450\u001b[0m\n",
      "\u001b[34mepoch 18/1000, training roc_auc_score 0.8235\u001b[0m\n",
      "\u001b[34mepoch 18/1000, validation roc_auc_score 0.7794, best validation roc_auc_score 0.7794\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 1/196, loss 0.1015\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 21/196, loss 0.2340\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 41/196, loss 0.1245\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 61/196, loss 0.1231\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 81/196, loss 0.1702\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 101/196, loss 0.1782\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 121/196, loss 0.1601\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 141/196, loss 0.1846\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 161/196, loss 0.1845\u001b[0m\n",
      "\u001b[34mepoch 19/1000, batch 181/196, loss 0.1664\u001b[0m\n",
      "\u001b[34mepoch 19/1000, training roc_auc_score 0.8280\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 1 out of 3\u001b[0m\n",
      "\u001b[34mepoch 19/1000, validation roc_auc_score 0.7713, best validation roc_auc_score 0.7794\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 1/196, loss 0.1636\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 21/196, loss 0.2021\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 41/196, loss 0.1511\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 61/196, loss 0.1479\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 81/196, loss 0.1615\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 101/196, loss 0.1087\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 121/196, loss 0.1483\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 141/196, loss 0.1544\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 161/196, loss 0.1504\u001b[0m\n",
      "\u001b[34mepoch 20/1000, batch 181/196, loss 0.1691\u001b[0m\n",
      "\u001b[34mepoch 20/1000, training roc_auc_score 0.8352\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 2 out of 3\u001b[0m\n",
      "\u001b[34mepoch 20/1000, validation roc_auc_score 0.7782, best validation roc_auc_score 0.7794\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 1/196, loss 0.2014\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 21/196, loss 0.1469\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 41/196, loss 0.1090\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 61/196, loss 0.2369\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 81/196, loss 0.0959\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 101/196, loss 0.1308\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 121/196, loss 0.2059\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 141/196, loss 0.2726\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 161/196, loss 0.1647\u001b[0m\n",
      "\u001b[34mepoch 21/1000, batch 181/196, loss 0.1899\u001b[0m\n",
      "\u001b[34mepoch 21/1000, training roc_auc_score 0.8329\u001b[0m\n",
      "\u001b[34mEarlyStopping counter: 3 out of 3\u001b[0m\n",
      "\u001b[34mepoch 21/1000, validation roc_auc_score 0.7712, best validation roc_auc_score 0.7794\u001b[0m\n",
      "\u001b[34mval roc_auc_score 0.7794\u001b[0m\n",
      "\u001b[34mtest roc_auc_score 0.7354\u001b[0m\n",
      "\u001b[34mUsing backend: pytorch\u001b[0m\n",
      "\u001b[34m2022-07-28 16:18:49,325 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-07-28 16:19:00 Uploading - Uploading generated training model\n",
      "2022-07-28 16:19:00 Completed - Training job completed\n",
      "Training seconds: 147\n",
      "Billable seconds: 147\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# JSON encode hyperparameters\n",
    "def json_encode_hyperparameters(hyperparameters):\n",
    "    return {str(k): json.dumps(v) for (k, v) in hyperparameters.items()}\n",
    "\n",
    "hyperparameters = json_encode_hyperparameters(\n",
    "    {\n",
    "        'dataset':'Tox21',\n",
    "        'model':'GCN',\n",
    "        'featurizer-type':'canonical',\n",
    "        'sagemaker_program':'classification.py',\n",
    "        'sagemaker_submit_directory':inputs\n",
    "    }\n",
    ")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri = '233488627969.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-dgllifesci-py36:1.0',\n",
    "    role = role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m5.4xlarge\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    sagemaker_session = sess\n",
    ")\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
